{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "\n",
    "In this coding assignment, you are requested to implement the Conditional GAN to make your model generates some MNIST images given the numbers you want.\n",
    "In detail, you need to implement the generator and the discriminator part.\n",
    "You will notice that the framework here is quite similar to assignment 3.\n",
    "But now, both the generator and the discriminator additionally take the numbers you want as input.\n",
    "You can build upon your last implementation.\n",
    "Fill the code in the file model.py and train the model.\n",
    "\n",
    "Here are some example results\n",
    "![title](example.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data_utils\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "\n",
    "from model import Generator, Discriminator\n",
    "from train import train_conditionGAN\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available()  else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hyperparameters are listed here. You maybe need to play a little bit with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "g_lr = 0.002\n",
    "d_lr = 0.0002\n",
    "batch_size = 128\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "            transforms.Scale(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, ), (0.5, )),\n",
    "        ])\n",
    "\n",
    "train_set = MNIST(root='.', train=True, transform=trans, download=True)\n",
    "train_loader = data_utils.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The training part. Due to the easy dataset and simplified model structure, the training is relatively fast.\n",
    "# In my case (Single Titan RTX) the training is finished in about 10 minutes.\n",
    "# You may need to balance the training of generator and discriminator (e.g. by tuning their learning rates) to\n",
    "# avoid a discriminator that is much stronger than the generator during training\n",
    "\n",
    "\n",
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "\n",
    "optim_G = torch.optim.Adam(G.parameters(), lr=g_lr, betas=(0.5, 0.999))\n",
    "optim_D = torch.optim.Adam(D.parameters(), lr=d_lr, betas=(0.5, 0.999))\n",
    "\n",
    "loss_f = nn.BCELoss()\n",
    "\n",
    "train_conditionGAN(G, D, optim_G, optim_D, loss_f, train_loader, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}