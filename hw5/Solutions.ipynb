{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a61a5cab-358c-4083-b737-5946403f1835",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "Lucas Bezerra, 171412, lucas.camaradantasbezerra@kaust.edu.sa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f8842-75c7-4d01-ae74-ca9303300885",
   "metadata": {},
   "source": [
    "### 1. Zero-Shot Learning and Vision-Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f839bb-654a-483d-9841-828123c2d689",
   "metadata": {},
   "source": [
    "1.1 Basic Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855d057-4ef1-4c6c-a354-4c091387e7e7",
   "metadata": {},
   "source": [
    "- <strong>What are the differences between GAZSL [2] and CIZSL [1]?</strong>\n",
    "\n",
    "In CIZSL an extra augmentation method is added. Besides the regular adversarial loss, the creativity-inspired loss is added when training the generator: hallucinated class descriptions $t^h$ are generated as linear combinations of the training set class descriptions ($t^h = \\alpha t_a^s + (1-\\alpha)t_b^s\\;,\\;\\alpha \\in \\left[0.2,0.8\\right]$). Then, for any $t^h \\sim p_{text}^h, z \\sim p_z$:\n",
    "\n",
    "1. Maximize the likelihood that the generator output (given hallucinated text $t^h, z$) is classified as real by the discriminator\n",
    "2. Maximize the entropy of the discriminator classifier the generator output (given hallucinated text $t^h, z$). This encourages the generator to create images that can't be classified by the discrminator as belonging to any particular class, thus preventing the generator from creating images that belong to any particular class.\n",
    "\n",
    "This extra augmentation heavily improves the performance of the model as compared to GAZSL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d95d9d0-c68e-4e13-9c18-84fc0526eb82",
   "metadata": {},
   "source": [
    "- <strong>How the creativity loss is connected with the classification head over\n",
    "classes? Why it can be helpful?</strong>\n",
    "\n",
    "As stated in the previous question, the creativity loss also encourages the generator to create images that the discriminator can't properly classify. This is helpful because it prevents the generator to creating images that belong to any of the classes it saw in the dataset, and thus encouraging creativity when generating new images, but not too much creativity, since the discriminator still needs to be tricked into believing the images are real, as in the traditional GAN setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c841921-210f-4bf2-8598-0e8cfa4495f9",
   "metadata": {},
   "source": [
    "- Run the code of CIZSL on one text-based dataset (e.g., CUB-wiki).\n",
    "Please report your performance using the provided hyperparameters (your\n",
    "performance may slightly different from the reported due to instability and\n",
    "different hyper-parameters). You can find the code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a472bb-4510-4fb4-ae7d-a94020646481",
   "metadata": {},
   "source": [
    "Interpolation between two real text features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99dead-0cee-4693-affd-18d5cccbb67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Interpolation between two real text features\n",
    "\n",
    "# Take all text descriptions\n",
    "text_feat_1 = np.array([dataset.train_text_feature[i, :] for i in labels])\n",
    "text_feat_2 = np.copy(text_feat_1)\n",
    "# Shuffle them to get random pairs of text descriptions\n",
    "np.random.shuffle(text_feat_1)  \n",
    "np.random.shuffle(text_feat_2)\n",
    "# Sample alpha (the interpolation coefficient used to create hallucinated text descriptions)\n",
    "alpha = np.random.uniform(low=.2, high=.8, size=len(labels))\n",
    "\n",
    "# Compute hallucinated text (combinations of text descriptions from training set)\n",
    "text_feat_mean = alpha*text_feat_1.T + (1-alpha)*text_feat_2.T\n",
    "# Normalize hallucinated features (l2-norm = 1)\n",
    "text_feat_mean = normalize(text_feat_mean.T, norm='l2', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d18597a-0dbb-4522-b6ae-cc7b55b64c67",
   "metadata": {},
   "source": [
    "Implement SM Divergence suitable for our case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "709764c9-d9cd-4cbc-8345-209751a4587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement SM Divergence suitable for our case.\n",
    "\n",
    "# Uniform distribution: 1/Ks for all classes\n",
    "q_shape = Variable(torch.FloatTensor(G_fake_C.data.size(0), G_fake_C.data.size(1))).cuda()\n",
    "q_shape.data.fill_(1.0 / G_fake_C.data.size(1))\n",
    "\n",
    "SM_ab = F.sigmoid(log_SM_ab(ones))\n",
    "# Compute Alpha\n",
    "SM_a = 0.2 + torch.div(SM_ab[0][0], 1.6666666666666667).cuda()\n",
    "# Compute Beta\n",
    "SM_b = 0.2 + torch.div(SM_ab[0][1], 1.6666666666666667).cuda()\n",
    "# Exponent: 1-Beta/(1-Alpha)\n",
    "pow_a_b = torch.div(1 - SM_a, 1 - SM_b)\n",
    "# Base: p_i^alpha * q_i^(1-alpha)\n",
    "# Summed over all i\n",
    "alpha_term = (torch.pow(G_fake_C + 1e-5, SM_a) * torch.pow(q_shape, 1 - SM_a)).sum(1)\n",
    "# Result: 1/(Beta-1)*[Sum(Base^Exponent)-1]\n",
    "entropy_GX_fake_vec = torch.div(torch.pow(alpha_term, pow_a_b) - 1, SM_b - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1888a6-d23b-45d4-a066-e86108eed400",
   "metadata": {},
   "source": [
    "Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76b92f0-44d1-458a-a47e-b2ac0ac178f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/camaral/code/gans_course/hw5/CIZSL\n",
      "Namespace(dataset='CUB', splitmode='hard', model_number=2, exp_name='Reproduce', main_dir='./', creativity_weight=0.1, validate=0, SM_Alpha=0.5, SM_Beta=0.9999, gpu='0', manualSeed=None, resume=None, disp_interval=20, save_interval=200, evl_interval=10)\n",
      "Random Seed:  2010\n",
      "100%|█████████████████████████████████████| 3001/3001 [2:15:51<00:00,  2.72s/it]\n",
      "===============\n",
      "===============\n",
      "Reproduce CUB hard\n",
      "Accuracy is 14.26%, and Generalized AUC is 11.53%\n",
      "Namespace(dataset='NAB', splitmode='hard', model_number=2, exp_name='Reproduce', main_dir='./', creativity_weight=0.1, validate=0, SM_Alpha=0.5, SM_Beta=0.9999, gpu='0', manualSeed=None, resume=None, disp_interval=20, save_interval=200, evl_interval=10)\n",
      "Random Seed:  6154\n",
      "100%|█████████████████████████████████████| 3001/3001 [8:51:46<00:00, 10.63s/it]\n",
      "===============\n",
      "===============\n",
      "Reproduce NAB hard\n",
      "Accuracy is 8.936%, and Generalized AUC is 6.715%\n",
      "Namespace(dataset='NAB', splitmode='easy', model_number=2, exp_name='Reproduce', main_dir='./', creativity_weight=1.0, validate=0, SM_Alpha=0.5, SM_Beta=0.9999, gpu='0', manualSeed=None, resume=None, disp_interval=20, save_interval=200, evl_interval=10)\n",
      "Random Seed:  6436\n",
      "100%|█████████████████████████████████████| 3001/3001 [8:58:02<00:00, 10.76s/it]\n",
      "===============\n",
      "===============\n",
      "Reproduce NAB easy\n",
      "Accuracy is 34.41%, and Generalized AUC is 22.02%\n",
      "Namespace(dataset='CUB', splitmode='easy', model_number=2, exp_name='Reproduce', main_dir='./', creativity_weight=0.0001, validate=0, SM_Alpha=0.5, SM_Beta=0.9999, gpu='0', manualSeed=None, resume=None, disp_interval=20, save_interval=200, evl_interval=10)\n",
      "Random Seed:  2380\n",
      "100%|█████████████████████████████████████| 3001/3001 [2:20:01<00:00,  2.80s/it]\n",
      "===============\n",
      "===============\n",
      "Reproduce CUB easy\n",
      "Accuracy is 40.98%, and Generalized AUC is 38.65%\n"
     ]
    }
   ],
   "source": [
    "# %%bash\n",
    "%cd CIZSL\n",
    "!./run.sh\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8167ef8c-ab97-4115-8a2a-c5206b61d82a",
   "metadata": {},
   "source": [
    "1.2 Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedb5a39-870f-4560-a481-88b97db5c379",
   "metadata": {},
   "source": [
    "- (25pt) Reproduce the results on attribute-based datasets including AWA2 and SUN. You can mainly build your network on top of GAZSL [2].\n",
    "\n",
    "Since GAZSL repository already includes the AWA2 and SUN datasets, I built CIZSL on top of it. Namely I added the creativity-loss based on hallucinated text to the GAZSL code, along with other minor modifications. The script \"/ZSL_GAN/train_GBU_CIZSL.py\" contains properly commented modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20672652-b947-4eba-bae3-d5afdc35136f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/camaral/code/gans_course/hw5/ZSL_GAN\n",
      "Running parameters:\n",
      "{\n",
      "    \"dataset\":\"AWA2\",\n",
      "    \"dataroot\":\"/home/camaral/code/gans_course/hw5/ZSL_GAN/data\",\n",
      "    \"matdataset\":true,\n",
      "    \"image_embedding\":\"res101\",\n",
      "    \"class_embedding\":\"att\",\n",
      "    \"preprocessing\":true,\n",
      "    \"standardization\":false,\n",
      "    \"validation\":false,\n",
      "    \"gpu\":\"0\",\n",
      "    \"exp_idx\":\"\",\n",
      "    \"manualSeed\":null,\n",
      "    \"resume\":null,\n",
      "    \"z_dim\":10,\n",
      "    \"disp_interval\":20,\n",
      "    \"save_interval\":200,\n",
      "    \"evl_interval\":40,\n",
      "    \"exp_name\":\"Reproduce\",\n",
      "    \"creativity_weight\":0.1,\n",
      "    \"validate\":0,\n",
      "    \"model_num\":2\n",
      "}\n",
      "Random Seed:  1445\n",
      "_netG_att(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=95, out_features=4096, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      ")\n",
      "_netD(\n",
      "  (D_shared): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (D_gan): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  (D_aux): Linear(in_features=4096, out_features=40, bias=True)\n",
      ")\n",
      "\u001b[31m The output dictionary is out/GBU_AWA2/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce\u001b[0m\n",
      "Iter-20; Was_D: 1.790; Euc_ls: 8.600; reg_ls: 2.897; G_loss: -0.344; D_loss_real: 1.432; D_loss_fake: -0.358; rl: 86.33%; fk: 44.73%\n",
      "Iter-40; Was_D: 1.478; Euc_ls: 7.921; reg_ls: 2.875; G_loss: 0.299; D_loss_real: 1.854; D_loss_fake: 0.376; rl: 91.31%; fk: 67.68%\n",
      "Iter-60; Was_D: 1.391; Euc_ls: 7.320; reg_ls: 2.855; G_loss: 0.369; D_loss_real: 1.736; D_loss_fake: 0.345; rl: 92.87%; fk: 90.33%\n",
      "Iter-80; Was_D: 1.518; Euc_ls: 6.752; reg_ls: 2.832; G_loss: 0.228; D_loss_real: 1.769; D_loss_fake: 0.251; rl: 92.77%; fk: 97.46%\n",
      "Iter-100; Was_D: 1.595; Euc_ls: 6.259; reg_ls: 2.812; G_loss: 0.156; D_loss_real: 1.751; D_loss_fake: 0.156; rl: 94.43%; fk: 99.12%\n",
      "Iter-120; Was_D: 1.619; Euc_ls: 5.883; reg_ls: 2.793; G_loss: 0.197; D_loss_real: 1.828; D_loss_fake: 0.210; rl: 94.82%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.42%\n",
      "H 29.78%  S->T 73.33%  U->T 18.68%  \n",
      "Iter-140; Was_D: 1.651; Euc_ls: 5.521; reg_ls: 2.776; G_loss: 0.150; D_loss_real: 1.788; D_loss_fake: 0.136; rl: 94.92%; fk: 100.00%\n",
      "Iter-160; Was_D: 1.658; Euc_ls: 5.328; reg_ls: 2.761; G_loss: 0.167; D_loss_real: 1.871; D_loss_fake: 0.213; rl: 95.41%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 61.74%\n",
      "H 32.95%  S->T 77.99%  U->T 20.89%  \n",
      "Iter-180; Was_D: 1.671; Euc_ls: 5.031; reg_ls: 2.747; G_loss: 0.249; D_loss_real: 1.938; D_loss_fake: 0.268; rl: 96.39%; fk: 100.00%\n",
      "Iter-200; Was_D: 1.690; Euc_ls: 4.781; reg_ls: 2.735; G_loss: 0.269; D_loss_real: 1.948; D_loss_fake: 0.259; rl: 97.07%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 63.74%\n",
      "H 30.78%  S->T 79.79%  U->T 19.07%  \n",
      "\u001b[31mSave model to out/GBU_AWA2/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_200.tar\u001b[0m\n",
      "Iter-220; Was_D: 1.681; Euc_ls: 4.573; reg_ls: 2.724; G_loss: 0.239; D_loss_real: 1.936; D_loss_fake: 0.255; rl: 97.85%; fk: 100.00%\n",
      "Iter-240; Was_D: 1.663; Euc_ls: 4.496; reg_ls: 2.714; G_loss: 0.257; D_loss_real: 1.951; D_loss_fake: 0.288; rl: 97.75%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 62.87%\n",
      "H 29.57%  S->T 81.59%  U->T 18.06%  \n",
      "Iter-260; Was_D: 1.696; Euc_ls: 4.120; reg_ls: 2.705; G_loss: 0.249; D_loss_real: 1.943; D_loss_fake: 0.247; rl: 98.54%; fk: 100.00%\n",
      "Iter-280; Was_D: 1.671; Euc_ls: 4.037; reg_ls: 2.697; G_loss: 0.250; D_loss_real: 1.942; D_loss_fake: 0.271; rl: 98.34%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 63.41%\n",
      "H 33.24%  S->T 84.19%  U->T 20.71%  \n",
      "Iter-300; Was_D: 1.705; Euc_ls: 3.836; reg_ls: 2.689; G_loss: 0.322; D_loss_real: 2.004; D_loss_fake: 0.299; rl: 99.02%; fk: 100.00%\n",
      "Iter-320; Was_D: 1.647; Euc_ls: 3.657; reg_ls: 2.682; G_loss: 0.195; D_loss_real: 1.892; D_loss_fake: 0.245; rl: 99.32%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 64.96%\n",
      "H 26.27%  S->T 84.98%  U->T 15.54%  \n",
      "Iter-340; Was_D: 1.683; Euc_ls: 3.703; reg_ls: 2.676; G_loss: 0.231; D_loss_real: 1.968; D_loss_fake: 0.284; rl: 99.61%; fk: 100.00%\n",
      "Iter-360; Was_D: 1.656; Euc_ls: 3.440; reg_ls: 2.669; G_loss: 0.305; D_loss_real: 1.963; D_loss_fake: 0.307; rl: 99.41%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 64.57%\n",
      "H 28.21%  S->T 85.78%  U->T 16.88%  \n",
      "Iter-380; Was_D: 1.680; Euc_ls: 3.280; reg_ls: 2.663; G_loss: 0.339; D_loss_real: 2.010; D_loss_fake: 0.329; rl: 99.51%; fk: 100.00%\n",
      "Iter-400; Was_D: 1.673; Euc_ls: 3.291; reg_ls: 2.657; G_loss: 0.349; D_loss_real: 2.036; D_loss_fake: 0.363; rl: 99.41%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 63.23%\n",
      "H 25.53%  S->T 86.21%  U->T 14.98%  \n",
      "\u001b[31mSave model to out/GBU_AWA2/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_400.tar\u001b[0m\n",
      "Iter-420; Was_D: 1.683; Euc_ls: 3.093; reg_ls: 2.652; G_loss: 0.290; D_loss_real: 1.959; D_loss_fake: 0.276; rl: 99.80%; fk: 100.00%\n",
      "Iter-440; Was_D: 1.661; Euc_ls: 3.116; reg_ls: 2.646; G_loss: 0.290; D_loss_real: 1.993; D_loss_fake: 0.332; rl: 99.41%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 63.22%\n",
      "H 21.80%  S->T 86.62%  U->T 12.47%  \n",
      "Iter-460; Was_D: 1.650; Euc_ls: 3.046; reg_ls: 2.641; G_loss: 0.305; D_loss_real: 1.977; D_loss_fake: 0.327; rl: 99.51%; fk: 99.90%\n",
      "Iter-480; Was_D: 1.691; Euc_ls: 2.848; reg_ls: 2.635; G_loss: 0.356; D_loss_real: 2.044; D_loss_fake: 0.352; rl: 99.80%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 62.24%\n",
      "H 24.10%  S->T 87.40%  U->T 13.98%  \n",
      "Iter-500; Was_D: 1.669; Euc_ls: 2.639; reg_ls: 2.630; G_loss: 0.288; D_loss_real: 1.937; D_loss_fake: 0.268; rl: 99.71%; fk: 100.00%\n",
      "Iter-520; Was_D: 1.662; Euc_ls: 2.759; reg_ls: 2.624; G_loss: 0.345; D_loss_real: 2.022; D_loss_fake: 0.360; rl: 99.61%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 62.41%\n",
      "H 21.41%  S->T 87.46%  U->T 12.20%  \n",
      "Iter-540; Was_D: 1.647; Euc_ls: 2.640; reg_ls: 2.619; G_loss: 0.258; D_loss_real: 1.851; D_loss_fake: 0.204; rl: 99.80%; fk: 100.00%\n",
      "Iter-560; Was_D: 1.667; Euc_ls: 2.550; reg_ls: 2.614; G_loss: 0.264; D_loss_real: 1.923; D_loss_fake: 0.257; rl: 99.71%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 61.90%\n",
      "H 19.22%  S->T 87.40%  U->T 10.80%  \n",
      "Iter-580; Was_D: 1.669; Euc_ls: 2.543; reg_ls: 2.608; G_loss: 0.289; D_loss_real: 1.956; D_loss_fake: 0.287; rl: 99.80%; fk: 100.00%\n",
      "Iter-600; Was_D: 1.688; Euc_ls: 2.437; reg_ls: 2.603; G_loss: 0.292; D_loss_real: 2.006; D_loss_fake: 0.318; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 61.14%\n",
      "H 19.86%  S->T 88.09%  U->T 11.19%  \n",
      "\u001b[31mSave model to out/GBU_AWA2/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_600.tar\u001b[0m\n",
      "Iter-620; Was_D: 1.705; Euc_ls: 2.332; reg_ls: 2.597; G_loss: 0.294; D_loss_real: 2.010; D_loss_fake: 0.305; rl: 99.80%; fk: 100.00%\n",
      "Iter-640; Was_D: 1.707; Euc_ls: 2.343; reg_ls: 2.591; G_loss: 0.274; D_loss_real: 1.988; D_loss_fake: 0.281; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 60.41%\n",
      "H 19.57%  S->T 88.26%  U->T 11.00%  \n",
      "Iter-660; Was_D: 1.709; Euc_ls: 2.337; reg_ls: 2.586; G_loss: 0.213; D_loss_real: 1.939; D_loss_fake: 0.230; rl: 100.00%; fk: 100.00%\n",
      "Iter-680; Was_D: 1.679; Euc_ls: 2.236; reg_ls: 2.580; G_loss: 0.237; D_loss_real: 1.916; D_loss_fake: 0.237; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 60.45%\n",
      "H 18.77%  S->T 88.04%  U->T 10.51%  \n",
      "Iter-700; Was_D: 1.697; Euc_ls: 2.540; reg_ls: 2.575; G_loss: 0.331; D_loss_real: 2.030; D_loss_fake: 0.334; rl: 100.00%; fk: 100.00%\n",
      "Iter-720; Was_D: 1.717; Euc_ls: 2.206; reg_ls: 2.569; G_loss: 0.224; D_loss_real: 1.957; D_loss_fake: 0.240; rl: 99.71%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 60.24%\n",
      "H 17.52%  S->T 88.72%  U->T 9.72%  \n",
      "Iter-740; Was_D: 1.724; Euc_ls: 2.133; reg_ls: 2.564; G_loss: 0.175; D_loss_real: 1.953; D_loss_fake: 0.228; rl: 99.90%; fk: 100.00%\n",
      "Iter-760; Was_D: 1.689; Euc_ls: 2.070; reg_ls: 2.558; G_loss: 0.212; D_loss_real: 1.948; D_loss_fake: 0.259; rl: 99.80%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 60.20%\n",
      "H 18.23%  S->T 88.12%  U->T 10.16%  \n",
      "Iter-780; Was_D: 1.725; Euc_ls: 2.078; reg_ls: 2.553; G_loss: 0.271; D_loss_real: 1.983; D_loss_fake: 0.258; rl: 100.00%; fk: 100.00%\n",
      "Iter-800; Was_D: 1.724; Euc_ls: 2.060; reg_ls: 2.547; G_loss: 0.190; D_loss_real: 1.918; D_loss_fake: 0.194; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 60.58%\n",
      "H 17.40%  S->T 88.69%  U->T 9.65%  \n",
      "\u001b[31mSave model to out/GBU_AWA2/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_800.tar\u001b[0m\n",
      "Iter-820; Was_D: 1.720; Euc_ls: 2.209; reg_ls: 2.542; G_loss: 0.186; D_loss_real: 1.897; D_loss_fake: 0.177; rl: 99.80%; fk: 100.00%\n",
      "Iter-840; Was_D: 1.729; Euc_ls: 1.925; reg_ls: 2.536; G_loss: 0.177; D_loss_real: 1.913; D_loss_fake: 0.184; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.77%\n",
      "H 20.49%  S->T 88.28%  U->T 11.59%  \n",
      "Iter-860; Was_D: 1.715; Euc_ls: 2.147; reg_ls: 2.530; G_loss: 0.209; D_loss_real: 1.933; D_loss_fake: 0.219; rl: 99.90%; fk: 100.00%\n",
      "Iter-880; Was_D: 1.763; Euc_ls: 2.072; reg_ls: 2.525; G_loss: 0.213; D_loss_real: 1.985; D_loss_fake: 0.222; rl: 99.80%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 60.43%\n",
      "H 17.06%  S->T 88.52%  U->T 9.44%  \n",
      "Iter-900; Was_D: 1.730; Euc_ls: 2.370; reg_ls: 2.519; G_loss: 0.169; D_loss_real: 1.922; D_loss_fake: 0.193; rl: 100.00%; fk: 100.00%\n",
      "Iter-920; Was_D: 1.718; Euc_ls: 2.150; reg_ls: 2.514; G_loss: 0.191; D_loss_real: 1.934; D_loss_fake: 0.216; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.69%\n",
      "H 17.07%  S->T 88.76%  U->T 9.44%  \n",
      "Iter-940; Was_D: 1.774; Euc_ls: 1.915; reg_ls: 2.508; G_loss: 0.202; D_loss_real: 1.957; D_loss_fake: 0.183; rl: 100.00%; fk: 100.00%\n",
      "Iter-960; Was_D: 1.729; Euc_ls: 1.822; reg_ls: 2.502; G_loss: 0.145; D_loss_real: 1.862; D_loss_fake: 0.133; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.72%\n",
      "H 16.89%  S->T 88.49%  U->T 9.34%  \n",
      "Iter-980; Was_D: 1.756; Euc_ls: 1.772; reg_ls: 2.497; G_loss: 0.174; D_loss_real: 1.920; D_loss_fake: 0.163; rl: 99.90%; fk: 100.00%\n",
      "Iter-1000; Was_D: 1.749; Euc_ls: 1.812; reg_ls: 2.491; G_loss: 0.159; D_loss_real: 1.882; D_loss_fake: 0.133; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.96%\n",
      "H 17.31%  S->T 88.95%  U->T 9.59%  \n",
      "\u001b[31mSave model to out/GBU_AWA2/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_1000.tar\u001b[0m\n",
      "Iter-1020; Was_D: 1.757; Euc_ls: 1.709; reg_ls: 2.486; G_loss: 0.136; D_loss_real: 1.880; D_loss_fake: 0.123; rl: 99.90%; fk: 100.00%\n",
      "Iter-1040; Was_D: 1.754; Euc_ls: 1.719; reg_ls: 2.480; G_loss: 0.202; D_loss_real: 1.900; D_loss_fake: 0.146; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.26%\n",
      "H 16.97%  S->T 88.69%  U->T 9.38%  \n",
      "Iter-1060; Was_D: 1.721; Euc_ls: 1.671; reg_ls: 2.474; G_loss: 0.150; D_loss_real: 1.892; D_loss_fake: 0.171; rl: 99.90%; fk: 100.00%\n",
      "Iter-1080; Was_D: 1.737; Euc_ls: 1.665; reg_ls: 2.468; G_loss: 0.137; D_loss_real: 1.917; D_loss_fake: 0.180; rl: 99.61%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.44%\n",
      "H 16.12%  S->T 88.76%  U->T 8.86%  \n",
      "Iter-1100; Was_D: 1.771; Euc_ls: 1.893; reg_ls: 2.463; G_loss: 0.122; D_loss_real: 1.896; D_loss_fake: 0.125; rl: 99.71%; fk: 100.00%\n",
      "Iter-1120; Was_D: 1.796; Euc_ls: 1.886; reg_ls: 2.457; G_loss: 0.133; D_loss_real: 1.912; D_loss_fake: 0.117; rl: 99.32%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.97%\n",
      "H 16.05%  S->T 88.67%  U->T 8.83%  \n",
      "Iter-1140; Was_D: 1.738; Euc_ls: 1.612; reg_ls: 2.451; G_loss: -0.002; D_loss_real: 1.787; D_loss_fake: 0.048; rl: 99.90%; fk: 100.00%\n",
      "Iter-1160; Was_D: 1.808; Euc_ls: 1.596; reg_ls: 2.445; G_loss: 0.055; D_loss_real: 1.833; D_loss_fake: 0.025; rl: 99.61%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.35%\n",
      "H 16.51%  S->T 89.14%  U->T 9.10%  \n",
      "Iter-1180; Was_D: 1.777; Euc_ls: 1.571; reg_ls: 2.440; G_loss: 0.126; D_loss_real: 1.876; D_loss_fake: 0.099; rl: 99.80%; fk: 100.00%\n",
      "Iter-1200; Was_D: 1.736; Euc_ls: 1.781; reg_ls: 2.434; G_loss: 0.018; D_loss_real: 1.787; D_loss_fake: 0.052; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.70%\n",
      "H 16.14%  S->T 89.05%  U->T 8.88%  \n",
      "\u001b[31mSave model to out/GBU_AWA2/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_1200.tar\u001b[0m\n",
      "Iter-1220; Was_D: 1.795; Euc_ls: 1.528; reg_ls: 2.428; G_loss: 0.061; D_loss_real: 1.849; D_loss_fake: 0.053; rl: 99.61%; fk: 100.00%\n",
      "Iter-1240; Was_D: 1.752; Euc_ls: 1.744; reg_ls: 2.422; G_loss: 0.030; D_loss_real: 1.780; D_loss_fake: 0.028; rl: 99.80%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.73%\n",
      "H 16.59%  S->T 88.53%  U->T 9.15%  \n",
      "Iter-1260; Was_D: 1.771; Euc_ls: 1.586; reg_ls: 2.416; G_loss: 0.059; D_loss_real: 1.804; D_loss_fake: 0.033; rl: 99.90%; fk: 100.00%\n",
      "Iter-1280; Was_D: 1.714; Euc_ls: 1.533; reg_ls: 2.410; G_loss: -0.018; D_loss_real: 1.716; D_loss_fake: 0.003; rl: 99.80%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.13%\n",
      "H 16.28%  S->T 88.89%  U->T 8.96%  \n",
      "Iter-1300; Was_D: 1.763; Euc_ls: 1.737; reg_ls: 2.404; G_loss: 0.022; D_loss_real: 1.805; D_loss_fake: 0.042; rl: 99.80%; fk: 100.00%\n",
      "Iter-1320; Was_D: 1.779; Euc_ls: 1.446; reg_ls: 2.398; G_loss: 0.007; D_loss_real: 1.747; D_loss_fake: -0.032; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.69%\n",
      "H 15.56%  S->T 89.02%  U->T 8.53%  \n",
      "Iter-1340; Was_D: 1.741; Euc_ls: 1.417; reg_ls: 2.392; G_loss: -0.036; D_loss_real: 1.722; D_loss_fake: -0.019; rl: 100.00%; fk: 100.00%\n",
      "Iter-1360; Was_D: 1.842; Euc_ls: 1.349; reg_ls: 2.386; G_loss: -0.001; D_loss_real: 1.810; D_loss_fake: -0.032; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.19%\n",
      "H 15.73%  S->T 88.66%  U->T 8.63%  \n",
      "Iter-1380; Was_D: 1.759; Euc_ls: 1.402; reg_ls: 2.380; G_loss: -0.045; D_loss_real: 1.725; D_loss_fake: -0.034; rl: 99.90%; fk: 100.00%\n",
      "Iter-1400; Was_D: 1.743; Euc_ls: 1.426; reg_ls: 2.374; G_loss: 0.015; D_loss_real: 1.784; D_loss_fake: 0.041; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 60.51%\n",
      "H 15.88%  S->T 89.12%  U->T 8.72%  \n",
      "\u001b[31mSave model to out/GBU_AWA2/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_1400.tar\u001b[0m\n",
      "Iter-1420; Was_D: 1.786; Euc_ls: 1.389; reg_ls: 2.368; G_loss: -0.041; D_loss_real: 1.750; D_loss_fake: -0.036; rl: 100.00%; fk: 100.00%\n",
      "Iter-1440; Was_D: 1.752; Euc_ls: 1.340; reg_ls: 2.362; G_loss: -0.065; D_loss_real: 1.703; D_loss_fake: -0.049; rl: 99.80%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.24%\n",
      "H 15.85%  S->T 88.77%  U->T 8.70%  \n",
      "Iter-1460; Was_D: 1.809; Euc_ls: 1.429; reg_ls: 2.355; G_loss: -0.058; D_loss_real: 1.738; D_loss_fake: -0.071; rl: 99.90%; fk: 100.00%\n",
      "Iter-1480; Was_D: 1.815; Euc_ls: 1.540; reg_ls: 2.349; G_loss: 0.001; D_loss_real: 1.818; D_loss_fake: 0.003; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.99%\n",
      "H 15.26%  S->T 88.80%  U->T 8.35%  \n",
      "Iter-1500; Was_D: 1.808; Euc_ls: 1.395; reg_ls: 2.343; G_loss: -0.067; D_loss_real: 1.747; D_loss_fake: -0.061; rl: 99.90%; fk: 100.00%\n",
      "Iter-1520; Was_D: 1.771; Euc_ls: 1.341; reg_ls: 2.336; G_loss: -0.036; D_loss_real: 1.763; D_loss_fake: -0.008; rl: 99.80%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.82%\n",
      "H 15.93%  S->T 88.82%  U->T 8.75%  \n",
      "Iter-1540; Was_D: 1.771; Euc_ls: 1.392; reg_ls: 2.330; G_loss: -0.054; D_loss_real: 1.746; D_loss_fake: -0.026; rl: 99.90%; fk: 100.00%\n",
      "Iter-1560; Was_D: 1.790; Euc_ls: 1.356; reg_ls: 2.323; G_loss: -0.016; D_loss_real: 1.791; D_loss_fake: 0.001; rl: 99.80%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 60.14%\n",
      "H 16.46%  S->T 88.92%  U->T 9.07%  \n",
      "Iter-1580; Was_D: 1.812; Euc_ls: 1.621; reg_ls: 2.317; G_loss: -0.112; D_loss_real: 1.697; D_loss_fake: -0.115; rl: 99.80%; fk: 100.00%\n",
      "Iter-1600; Was_D: 1.753; Euc_ls: 1.351; reg_ls: 2.310; G_loss: -0.075; D_loss_real: 1.729; D_loss_fake: -0.025; rl: 99.80%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.45%\n",
      "H 15.00%  S->T 88.79%  U->T 8.19%  \n",
      "\u001b[31mSave model to out/GBU_AWA2/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_1600.tar\u001b[0m\n",
      "Iter-1620; Was_D: 1.795; Euc_ls: 1.348; reg_ls: 2.303; G_loss: -0.104; D_loss_real: 1.683; D_loss_fake: -0.112; rl: 99.90%; fk: 100.00%\n",
      "Iter-1640; Was_D: 1.808; Euc_ls: 1.318; reg_ls: 2.297; G_loss: -0.036; D_loss_real: 1.763; D_loss_fake: -0.045; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.85%\n",
      "H 16.03%  S->T 88.77%  U->T 8.81%  \n",
      "Iter-1660; Was_D: 1.849; Euc_ls: 1.302; reg_ls: 2.290; G_loss: -0.094; D_loss_real: 1.768; D_loss_fake: -0.081; rl: 99.90%; fk: 100.00%\n",
      "Iter-1680; Was_D: 1.844; Euc_ls: 1.295; reg_ls: 2.283; G_loss: -0.055; D_loss_real: 1.806; D_loss_fake: -0.038; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.76%\n",
      "H 16.08%  S->T 88.69%  U->T 8.84%  \n",
      "Iter-1700; Was_D: 1.812; Euc_ls: 1.320; reg_ls: 2.276; G_loss: -0.144; D_loss_real: 1.657; D_loss_fake: -0.155; rl: 99.90%; fk: 100.00%\n",
      "Iter-1720; Was_D: 1.790; Euc_ls: 1.317; reg_ls: 2.269; G_loss: -0.038; D_loss_real: 1.763; D_loss_fake: -0.027; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.01%\n",
      "H 15.89%  S->T 88.67%  U->T 8.73%  \n",
      "Iter-1740; Was_D: 1.844; Euc_ls: 1.342; reg_ls: 2.262; G_loss: -0.030; D_loss_real: 1.814; D_loss_fake: -0.030; rl: 99.80%; fk: 100.00%\n",
      "Iter-1760; Was_D: 1.810; Euc_ls: 1.270; reg_ls: 2.255; G_loss: -0.082; D_loss_real: 1.737; D_loss_fake: -0.073; rl: 99.71%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.16%\n",
      "H 16.55%  S->T 89.05%  U->T 9.12%  \n",
      "Iter-1780; Was_D: 1.838; Euc_ls: 1.528; reg_ls: 2.248; G_loss: -0.093; D_loss_real: 1.745; D_loss_fake: -0.093; rl: 100.00%; fk: 100.00%\n",
      "Iter-1800; Was_D: 1.842; Euc_ls: 1.273; reg_ls: 2.241; G_loss: -0.164; D_loss_real: 1.654; D_loss_fake: -0.188; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.53%\n",
      "H 16.50%  S->T 88.78%  U->T 9.10%  \n",
      "\u001b[31mSave model to out/GBU_AWA2/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_1800.tar\u001b[0m\n",
      "Iter-1820; Was_D: 1.822; Euc_ls: 1.272; reg_ls: 2.234; G_loss: -0.139; D_loss_real: 1.685; D_loss_fake: -0.137; rl: 99.90%; fk: 100.00%\n",
      "Iter-1840; Was_D: 1.810; Euc_ls: 1.283; reg_ls: 2.227; G_loss: -0.142; D_loss_real: 1.699; D_loss_fake: -0.110; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.28%\n",
      "H 16.59%  S->T 89.01%  U->T 9.15%  \n",
      "Iter-1860; Was_D: 1.848; Euc_ls: 1.306; reg_ls: 2.219; G_loss: -0.149; D_loss_real: 1.698; D_loss_fake: -0.150; rl: 99.80%; fk: 100.00%\n",
      "Iter-1880; Was_D: 1.864; Euc_ls: 1.355; reg_ls: 2.212; G_loss: -0.111; D_loss_real: 1.749; D_loss_fake: -0.115; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.17%\n",
      "H 16.52%  S->T 89.04%  U->T 9.10%  \n",
      "Iter-1900; Was_D: 1.877; Euc_ls: 1.300; reg_ls: 2.205; G_loss: -0.058; D_loss_real: 1.824; D_loss_fake: -0.053; rl: 99.90%; fk: 100.00%\n",
      "Iter-1920; Was_D: 1.821; Euc_ls: 1.239; reg_ls: 2.198; G_loss: -0.134; D_loss_real: 1.702; D_loss_fake: -0.119; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.66%\n",
      "H 15.70%  S->T 88.91%  U->T 8.61%  \n",
      "Iter-1940; Was_D: 1.845; Euc_ls: 1.310; reg_ls: 2.190; G_loss: -0.166; D_loss_real: 1.682; D_loss_fake: -0.162; rl: 99.90%; fk: 100.00%\n",
      "Iter-1960; Was_D: 1.833; Euc_ls: 1.270; reg_ls: 2.183; G_loss: -0.142; D_loss_real: 1.706; D_loss_fake: -0.127; rl: 99.80%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 60.30%\n",
      "H 18.27%  S->T 88.89%  U->T 10.18%  \n",
      "Iter-1980; Was_D: 1.864; Euc_ls: 1.230; reg_ls: 2.175; G_loss: -0.072; D_loss_real: 1.756; D_loss_fake: -0.109; rl: 99.90%; fk: 100.00%\n",
      "Iter-2000; Was_D: 1.879; Euc_ls: 1.283; reg_ls: 2.168; G_loss: -0.098; D_loss_real: 1.780; D_loss_fake: -0.099; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.38%\n",
      "H 15.27%  S->T 89.03%  U->T 8.35%  \n",
      "\u001b[31mSave model to out/GBU_AWA2/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_2000.tar\u001b[0m\n",
      "Iter-2020; Was_D: 1.816; Euc_ls: 1.520; reg_ls: 2.160; G_loss: -0.172; D_loss_real: 1.649; D_loss_fake: -0.167; rl: 99.80%; fk: 100.00%\n",
      "Iter-2040; Was_D: 1.885; Euc_ls: 1.253; reg_ls: 2.153; G_loss: -0.136; D_loss_real: 1.793; D_loss_fake: -0.092; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.70%\n",
      "H 17.17%  S->T 89.05%  U->T 9.50%  \n",
      "Iter-2060; Was_D: 1.827; Euc_ls: 1.283; reg_ls: 2.146; G_loss: -0.165; D_loss_real: 1.636; D_loss_fake: -0.191; rl: 100.00%; fk: 100.00%\n",
      "Iter-2080; Was_D: 1.846; Euc_ls: 1.522; reg_ls: 2.138; G_loss: -0.115; D_loss_real: 1.748; D_loss_fake: -0.098; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.72%\n",
      "H 18.42%  S->T 88.96%  U->T 10.28%  \n",
      "Iter-2100; Was_D: 1.894; Euc_ls: 1.345; reg_ls: 2.131; G_loss: -0.206; D_loss_real: 1.704; D_loss_fake: -0.190; rl: 99.71%; fk: 100.00%\n",
      "Iter-2120; Was_D: 1.852; Euc_ls: 1.233; reg_ls: 2.123; G_loss: -0.110; D_loss_real: 1.737; D_loss_fake: -0.115; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 60.21%\n",
      "H 16.88%  S->T 88.82%  U->T 9.33%  \n",
      "Iter-2140; Was_D: 1.850; Euc_ls: 1.306; reg_ls: 2.116; G_loss: -0.183; D_loss_real: 1.672; D_loss_fake: -0.178; rl: 99.90%; fk: 100.00%\n",
      "Iter-2160; Was_D: 1.862; Euc_ls: 1.263; reg_ls: 2.108; G_loss: -0.102; D_loss_real: 1.765; D_loss_fake: -0.097; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.27%\n",
      "H 17.34%  S->T 88.98%  U->T 9.60%  \n",
      "Iter-2180; Was_D: 1.831; Euc_ls: 1.281; reg_ls: 2.101; G_loss: -0.164; D_loss_real: 1.694; D_loss_fake: -0.137; rl: 99.61%; fk: 100.00%\n",
      "Iter-2200; Was_D: 1.839; Euc_ls: 1.244; reg_ls: 2.093; G_loss: -0.103; D_loss_real: 1.741; D_loss_fake: -0.098; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.94%\n",
      "H 16.49%  S->T 88.98%  U->T 9.09%  \n",
      "\u001b[31mSave model to out/GBU_AWA2/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_2200.tar\u001b[0m\n",
      "Iter-2220; Was_D: 1.838; Euc_ls: 1.251; reg_ls: 2.085; G_loss: -0.174; D_loss_real: 1.674; D_loss_fake: -0.164; rl: 100.00%; fk: 100.00%\n",
      "Iter-2240; Was_D: 1.845; Euc_ls: 1.268; reg_ls: 2.078; G_loss: -0.136; D_loss_real: 1.692; D_loss_fake: -0.153; rl: 99.80%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 60.42%\n",
      "H 17.07%  S->T 89.00%  U->T 9.44%  \n",
      "Iter-2260; Was_D: 1.880; Euc_ls: 1.248; reg_ls: 2.070; G_loss: -0.132; D_loss_real: 1.731; D_loss_fake: -0.150; rl: 100.00%; fk: 100.00%\n",
      "Iter-2280; Was_D: 1.888; Euc_ls: 1.481; reg_ls: 2.062; G_loss: -0.113; D_loss_real: 1.783; D_loss_fake: -0.105; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.48%\n",
      "H 17.83%  S->T 88.99%  U->T 9.91%  \n",
      "Iter-2300; Was_D: 1.868; Euc_ls: 1.272; reg_ls: 2.055; G_loss: -0.180; D_loss_real: 1.683; D_loss_fake: -0.185; rl: 99.90%; fk: 100.00%\n",
      "Iter-2320; Was_D: 1.862; Euc_ls: 1.316; reg_ls: 2.047; G_loss: -0.188; D_loss_real: 1.698; D_loss_fake: -0.164; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.82%\n",
      "H 17.31%  S->T 89.03%  U->T 9.59%  \n",
      "Iter-2340; Was_D: 1.871; Euc_ls: 1.256; reg_ls: 2.039; G_loss: -0.150; D_loss_real: 1.731; D_loss_fake: -0.139; rl: 99.71%; fk: 100.00%\n",
      "Iter-2360; Was_D: 1.857; Euc_ls: 1.251; reg_ls: 2.031; G_loss: -0.165; D_loss_real: 1.710; D_loss_fake: -0.148; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 61.88%\n",
      "H 17.44%  S->T 88.44%  U->T 9.67%  \n",
      "Iter-2380; Was_D: 1.894; Euc_ls: 1.275; reg_ls: 2.024; G_loss: -0.175; D_loss_real: 1.746; D_loss_fake: -0.148; rl: 99.90%; fk: 100.00%\n",
      "Iter-2400; Was_D: 1.870; Euc_ls: 1.327; reg_ls: 2.016; G_loss: -0.183; D_loss_real: 1.708; D_loss_fake: -0.162; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 60.31%\n",
      "H 16.37%  S->T 88.96%  U->T 9.01%  \n",
      "\u001b[31mSave model to out/GBU_AWA2/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_2400.tar\u001b[0m\n",
      "Iter-2420; Was_D: 1.923; Euc_ls: 1.461; reg_ls: 2.008; G_loss: -0.100; D_loss_real: 1.803; D_loss_fake: -0.120; rl: 99.90%; fk: 100.00%\n",
      "Iter-2440; Was_D: 1.879; Euc_ls: 1.240; reg_ls: 2.001; G_loss: -0.163; D_loss_real: 1.710; D_loss_fake: -0.169; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.57%\n",
      "H 17.22%  S->T 88.87%  U->T 9.53%  \n",
      "Iter-2460; Was_D: 1.865; Euc_ls: 1.283; reg_ls: 1.993; G_loss: -0.084; D_loss_real: 1.822; D_loss_fake: -0.043; rl: 100.00%; fk: 100.00%\n",
      "Iter-2480; Was_D: 1.879; Euc_ls: 1.369; reg_ls: 1.985; G_loss: -0.203; D_loss_real: 1.690; D_loss_fake: -0.190; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.58%\n",
      "H 18.09%  S->T 89.04%  U->T 10.07%  \n",
      "Iter-2500; Was_D: 1.887; Euc_ls: 1.243; reg_ls: 1.978; G_loss: -0.159; D_loss_real: 1.734; D_loss_fake: -0.154; rl: 99.90%; fk: 100.00%\n",
      "Iter-2520; Was_D: 1.877; Euc_ls: 1.277; reg_ls: 1.970; G_loss: -0.109; D_loss_real: 1.795; D_loss_fake: -0.082; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 61.08%\n",
      "H 18.23%  S->T 88.86%  U->T 10.16%  \n",
      "Iter-2540; Was_D: 1.933; Euc_ls: 1.484; reg_ls: 1.962; G_loss: -0.072; D_loss_real: 1.821; D_loss_fake: -0.112; rl: 99.71%; fk: 100.00%\n",
      "Iter-2560; Was_D: 1.906; Euc_ls: 1.278; reg_ls: 1.955; G_loss: -0.146; D_loss_real: 1.748; D_loss_fake: -0.158; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.67%\n",
      "H 16.98%  S->T 88.73%  U->T 9.39%  \n",
      "Iter-2580; Was_D: 1.859; Euc_ls: 1.237; reg_ls: 1.947; G_loss: -0.117; D_loss_real: 1.710; D_loss_fake: -0.149; rl: 99.90%; fk: 100.00%\n",
      "Iter-2600; Was_D: 1.929; Euc_ls: 1.157; reg_ls: 1.939; G_loss: -0.133; D_loss_real: 1.812; D_loss_fake: -0.117; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 60.31%\n",
      "H 16.57%  S->T 88.90%  U->T 9.13%  \n",
      "\u001b[31mSave model to out/GBU_AWA2/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_2600.tar\u001b[0m\n",
      "Iter-2620; Was_D: 1.887; Euc_ls: 1.392; reg_ls: 1.931; G_loss: -0.139; D_loss_real: 1.748; D_loss_fake: -0.139; rl: 99.90%; fk: 100.00%\n",
      "Iter-2640; Was_D: 1.929; Euc_ls: 1.208; reg_ls: 1.924; G_loss: -0.123; D_loss_real: 1.782; D_loss_fake: -0.147; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.62%\n",
      "H 17.30%  S->T 88.81%  U->T 9.58%  \n",
      "Iter-2660; Was_D: 1.915; Euc_ls: 1.213; reg_ls: 1.916; G_loss: -0.109; D_loss_real: 1.829; D_loss_fake: -0.086; rl: 100.00%; fk: 100.00%\n",
      "Iter-2680; Was_D: 1.944; Euc_ls: 1.260; reg_ls: 1.908; G_loss: -0.119; D_loss_real: 1.791; D_loss_fake: -0.154; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.77%\n",
      "H 19.59%  S->T 88.91%  U->T 11.01%  \n",
      "Iter-2700; Was_D: 1.893; Euc_ls: 1.424; reg_ls: 1.901; G_loss: -0.153; D_loss_real: 1.749; D_loss_fake: -0.144; rl: 100.00%; fk: 100.00%\n",
      "Iter-2720; Was_D: 1.908; Euc_ls: 1.262; reg_ls: 1.893; G_loss: -0.171; D_loss_real: 1.735; D_loss_fake: -0.173; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 60.78%\n",
      "H 19.35%  S->T 88.76%  U->T 10.86%  \n",
      "Iter-2740; Was_D: 1.905; Euc_ls: 1.224; reg_ls: 1.886; G_loss: -0.091; D_loss_real: 1.804; D_loss_fake: -0.101; rl: 99.80%; fk: 100.00%\n",
      "Iter-2760; Was_D: 1.941; Euc_ls: 1.166; reg_ls: 1.878; G_loss: -0.164; D_loss_real: 1.763; D_loss_fake: -0.178; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.88%\n",
      "H 16.93%  S->T 88.76%  U->T 9.36%  \n",
      "Iter-2780; Was_D: 1.912; Euc_ls: 1.177; reg_ls: 1.870; G_loss: -0.164; D_loss_real: 1.747; D_loss_fake: -0.165; rl: 99.90%; fk: 100.00%\n",
      "Iter-2800; Was_D: 1.899; Euc_ls: 1.214; reg_ls: 1.863; G_loss: -0.145; D_loss_real: 1.736; D_loss_fake: -0.164; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 61.04%\n",
      "H 18.31%  S->T 88.86%  U->T 10.21%  \n",
      "\u001b[31mSave model to out/GBU_AWA2/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_2800.tar\u001b[0m\n",
      "Iter-2820; Was_D: 1.911; Euc_ls: 1.164; reg_ls: 1.855; G_loss: -0.088; D_loss_real: 1.823; D_loss_fake: -0.088; rl: 100.00%; fk: 100.00%\n",
      "Iter-2840; Was_D: 1.914; Euc_ls: 1.191; reg_ls: 1.847; G_loss: -0.113; D_loss_real: 1.782; D_loss_fake: -0.132; rl: 99.71%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 60.04%\n",
      "H 19.51%  S->T 88.83%  U->T 10.96%  \n",
      "Iter-2860; Was_D: 1.936; Euc_ls: 1.228; reg_ls: 1.840; G_loss: -0.148; D_loss_real: 1.803; D_loss_fake: -0.132; rl: 100.00%; fk: 100.00%\n",
      "Iter-2880; Was_D: 1.879; Euc_ls: 1.229; reg_ls: 1.832; G_loss: -0.120; D_loss_real: 1.782; D_loss_fake: -0.096; rl: 99.80%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.57%\n",
      "H 19.26%  S->T 89.00%  U->T 10.80%  \n",
      "Iter-2900; Was_D: 1.896; Euc_ls: 1.205; reg_ls: 1.825; G_loss: -0.170; D_loss_real: 1.733; D_loss_fake: -0.163; rl: 99.90%; fk: 100.00%\n",
      "Iter-2920; Was_D: 1.967; Euc_ls: 1.215; reg_ls: 1.817; G_loss: -0.143; D_loss_real: 1.783; D_loss_fake: -0.184; rl: 99.80%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.03%\n",
      "H 19.93%  S->T 88.83%  U->T 11.23%  \n",
      "Iter-2940; Was_D: 1.901; Euc_ls: 1.184; reg_ls: 1.810; G_loss: -0.169; D_loss_real: 1.755; D_loss_fake: -0.146; rl: 99.80%; fk: 100.00%\n",
      "Iter-2960; Was_D: 1.915; Euc_ls: 1.217; reg_ls: 1.802; G_loss: -0.169; D_loss_real: 1.745; D_loss_fake: -0.170; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 59.66%\n",
      "H 18.40%  S->T 88.85%  U->T 10.26%  \n",
      "Iter-2980; Was_D: 1.905; Euc_ls: 1.234; reg_ls: 1.795; G_loss: -0.140; D_loss_real: 1.752; D_loss_fake: -0.153; rl: 99.71%; fk: 100.00%\n",
      "Iter-3000; Was_D: 1.899; Euc_ls: 1.188; reg_ls: 1.788; G_loss: -0.137; D_loss_real: 1.797; D_loss_fake: -0.102; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 60.36%\n",
      "H 18.43%  S->T 88.59%  U->T 10.29%  \n",
      "\u001b[31mSave model to out/GBU_AWA2/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_3000.tar\u001b[0m\n",
      "===============\n",
      "===============\n",
      "Reproduce AWA2\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/camaral/code/gans_course/hw5/ZSL_GAN/train_GBU_CIZSL.py\", line 664, in <module>\n",
      "    print(\"Accuracy is {:.4}%, and Generalized AUC is {:.4}%\".format(result.best_acc, result.best_auc))\n",
      "AttributeError: 'NoneType' object has no attribute 'best_acc'\n",
      "/home/camaral/code/gans_course/hw5\n"
     ]
    }
   ],
   "source": [
    "%cd ZSL_GAN\n",
    "!python train_GBU_CIZSL.py --dataset 'AWA2' --preprocessing --z_dim 10 --creativity_weight 0.1\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6da01412-4304-4e44-af8c-caa1c3819b90",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/camaral/code/gans_course/hw5/ZSL_GAN\n",
      "Running parameters:\n",
      "{\n",
      "    \"dataset\":\"SUN\",\n",
      "    \"dataroot\":\"/home/camaral/code/gans_course/hw5/ZSL_GAN/data\",\n",
      "    \"matdataset\":true,\n",
      "    \"image_embedding\":\"res101\",\n",
      "    \"class_embedding\":\"att\",\n",
      "    \"preprocessing\":true,\n",
      "    \"standardization\":false,\n",
      "    \"validation\":false,\n",
      "    \"gpu\":\"0\",\n",
      "    \"exp_idx\":\"\",\n",
      "    \"manualSeed\":null,\n",
      "    \"resume\":null,\n",
      "    \"z_dim\":10,\n",
      "    \"disp_interval\":20,\n",
      "    \"save_interval\":200,\n",
      "    \"evl_interval\":40,\n",
      "    \"exp_name\":\"Reproduce\",\n",
      "    \"creativity_weight\":0.1,\n",
      "    \"validate\":0,\n",
      "    \"model_num\":2\n",
      "}\n",
      "Random Seed:  9908\n",
      "_netG_att(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=112, out_features=4096, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      ")\n",
      "_netD(\n",
      "  (D_shared): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (D_gan): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  (D_aux): Linear(in_features=4096, out_features=645, bias=True)\n",
      ")\n",
      "\u001b[31m The output dictionary is out/GBU_SUN/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce\u001b[0m\n",
      "Iter-20; Was_D: 1.582; Euc_ls: 8.877; reg_ls: 2.923; G_loss: -0.120; D_loss_real: 1.471; D_loss_fake: -0.112; rl: 33.11%; fk: 0.29%\n",
      "Iter-40; Was_D: 1.263; Euc_ls: 8.236; reg_ls: 2.890; G_loss: 0.739; D_loss_real: 2.093; D_loss_fake: 0.830; rl: 48.34%; fk: 0.29%\n",
      "Iter-60; Was_D: 1.424; Euc_ls: 8.350; reg_ls: 2.845; G_loss: 0.657; D_loss_real: 2.022; D_loss_fake: 0.598; rl: 56.15%; fk: 1.66%\n",
      "Iter-80; Was_D: 1.442; Euc_ls: 8.308; reg_ls: 2.801; G_loss: 0.613; D_loss_real: 2.106; D_loss_fake: 0.664; rl: 58.11%; fk: 11.43%\n",
      "Iter-100; Was_D: 1.428; Euc_ls: 7.997; reg_ls: 2.761; G_loss: 0.511; D_loss_real: 1.919; D_loss_fake: 0.490; rl: 60.84%; fk: 22.27%\n",
      "Iter-120; Was_D: 1.410; Euc_ls: 8.061; reg_ls: 2.726; G_loss: 0.441; D_loss_real: 1.885; D_loss_fake: 0.474; rl: 61.04%; fk: 42.87%\n",
      "20nn Classifer: \n",
      "Accuracy is 39.24%\n",
      "H 10.95%  S->T 10.43%  U->T 11.53%  \n",
      "Iter-140; Was_D: 1.403; Euc_ls: 7.819; reg_ls: 2.693; G_loss: 0.531; D_loss_real: 1.900; D_loss_fake: 0.497; rl: 64.26%; fk: 59.77%\n",
      "Iter-160; Was_D: 1.363; Euc_ls: 7.576; reg_ls: 2.661; G_loss: 0.430; D_loss_real: 1.866; D_loss_fake: 0.503; rl: 63.18%; fk: 68.26%\n",
      "20nn Classifer: \n",
      "Accuracy is 43.75%\n",
      "H 15.13%  S->T 14.61%  U->T 15.69%  \n",
      "Iter-180; Was_D: 1.343; Euc_ls: 7.619; reg_ls: 2.631; G_loss: 0.445; D_loss_real: 1.778; D_loss_fake: 0.435; rl: 68.65%; fk: 78.81%\n",
      "Iter-200; Was_D: 1.338; Euc_ls: 7.453; reg_ls: 2.601; G_loss: 0.451; D_loss_real: 1.814; D_loss_fake: 0.477; rl: 69.73%; fk: 85.25%\n",
      "20nn Classifer: \n",
      "Accuracy is 47.50%\n",
      "H 16.01%  S->T 17.17%  U->T 15.00%  \n",
      "\u001b[31mSave model to out/GBU_SUN/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_200.tar\u001b[0m\n",
      "Iter-220; Was_D: 1.320; Euc_ls: 7.764; reg_ls: 2.572; G_loss: 0.426; D_loss_real: 1.802; D_loss_fake: 0.483; rl: 71.09%; fk: 89.26%\n",
      "Iter-240; Was_D: 1.361; Euc_ls: 7.777; reg_ls: 2.544; G_loss: 0.448; D_loss_real: 1.853; D_loss_fake: 0.493; rl: 76.76%; fk: 91.89%\n",
      "20nn Classifer: \n",
      "Accuracy is 50.42%\n",
      "H 18.55%  S->T 19.15%  U->T 17.99%  \n",
      "Iter-260; Was_D: 1.339; Euc_ls: 7.581; reg_ls: 2.516; G_loss: 0.480; D_loss_real: 1.903; D_loss_fake: 0.564; rl: 77.44%; fk: 94.04%\n",
      "Iter-280; Was_D: 1.354; Euc_ls: 7.217; reg_ls: 2.488; G_loss: 0.442; D_loss_real: 1.805; D_loss_fake: 0.451; rl: 79.30%; fk: 96.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 50.76%\n",
      "H 19.07%  S->T 20.04%  U->T 18.19%  \n",
      "Iter-300; Was_D: 1.340; Euc_ls: 7.432; reg_ls: 2.461; G_loss: 0.558; D_loss_real: 1.960; D_loss_fake: 0.620; rl: 83.89%; fk: 96.68%\n",
      "Iter-320; Was_D: 1.364; Euc_ls: 7.245; reg_ls: 2.435; G_loss: 0.540; D_loss_real: 1.901; D_loss_fake: 0.537; rl: 83.20%; fk: 96.78%\n",
      "20nn Classifer: \n",
      "Accuracy is 52.36%\n",
      "H 19.45%  S->T 21.09%  U->T 18.06%  \n",
      "Iter-340; Was_D: 1.379; Euc_ls: 7.541; reg_ls: 2.409; G_loss: 0.567; D_loss_real: 1.938; D_loss_fake: 0.559; rl: 86.72%; fk: 98.14%\n",
      "Iter-360; Was_D: 1.374; Euc_ls: 7.352; reg_ls: 2.384; G_loss: 0.645; D_loss_real: 2.012; D_loss_fake: 0.638; rl: 88.38%; fk: 97.17%\n",
      "20nn Classifer: \n",
      "Accuracy is 53.54%\n",
      "H 19.46%  S->T 21.01%  U->T 18.13%  \n",
      "Iter-380; Was_D: 1.349; Euc_ls: 7.361; reg_ls: 2.360; G_loss: 0.640; D_loss_real: 1.994; D_loss_fake: 0.645; rl: 90.33%; fk: 97.95%\n",
      "Iter-400; Was_D: 1.333; Euc_ls: 7.445; reg_ls: 2.335; G_loss: 0.603; D_loss_real: 1.949; D_loss_fake: 0.616; rl: 91.41%; fk: 98.34%\n",
      "20nn Classifer: \n",
      "Accuracy is 53.75%\n",
      "H 20.57%  S->T 22.67%  U->T 18.82%  \n",
      "\u001b[31mSave model to out/GBU_SUN/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_400.tar\u001b[0m\n",
      "Iter-420; Was_D: 1.339; Euc_ls: 7.239; reg_ls: 2.312; G_loss: 0.573; D_loss_real: 1.913; D_loss_fake: 0.574; rl: 92.97%; fk: 98.24%\n",
      "Iter-440; Was_D: 1.349; Euc_ls: 7.103; reg_ls: 2.289; G_loss: 0.690; D_loss_real: 2.032; D_loss_fake: 0.683; rl: 95.21%; fk: 98.93%\n",
      "20nn Classifer: \n",
      "Accuracy is 54.72%\n",
      "H 20.92%  S->T 23.02%  U->T 19.17%  \n",
      "Iter-460; Was_D: 1.356; Euc_ls: 7.014; reg_ls: 2.266; G_loss: 0.603; D_loss_real: 1.998; D_loss_fake: 0.642; rl: 95.90%; fk: 99.02%\n",
      "Iter-480; Was_D: 1.379; Euc_ls: 7.274; reg_ls: 2.243; G_loss: 0.660; D_loss_real: 2.061; D_loss_fake: 0.682; rl: 95.80%; fk: 99.22%\n",
      "20nn Classifer: \n",
      "Accuracy is 54.37%\n",
      "H 21.86%  S->T 24.11%  U->T 20.00%  \n",
      "Iter-500; Was_D: 1.345; Euc_ls: 7.110; reg_ls: 2.222; G_loss: 0.564; D_loss_real: 1.904; D_loss_fake: 0.559; rl: 97.85%; fk: 99.22%\n",
      "Iter-520; Was_D: 1.335; Euc_ls: 7.403; reg_ls: 2.200; G_loss: 0.661; D_loss_real: 2.023; D_loss_fake: 0.688; rl: 98.14%; fk: 99.61%\n",
      "20nn Classifer: \n",
      "Accuracy is 55.35%\n",
      "H 21.79%  S->T 24.34%  U->T 19.72%  \n",
      "Iter-540; Was_D: 1.333; Euc_ls: 7.562; reg_ls: 2.178; G_loss: 0.670; D_loss_real: 2.018; D_loss_fake: 0.686; rl: 99.02%; fk: 99.41%\n",
      "Iter-560; Was_D: 1.346; Euc_ls: 7.178; reg_ls: 2.157; G_loss: 0.688; D_loss_real: 2.005; D_loss_fake: 0.659; rl: 99.41%; fk: 99.80%\n",
      "20nn Classifer: \n",
      "Accuracy is 55.49%\n",
      "H 21.68%  S->T 25.19%  U->T 19.03%  \n",
      "Iter-580; Was_D: 1.356; Euc_ls: 7.098; reg_ls: 2.137; G_loss: 0.752; D_loss_real: 2.134; D_loss_fake: 0.778; rl: 99.51%; fk: 99.61%\n",
      "Iter-600; Was_D: 1.381; Euc_ls: 7.017; reg_ls: 2.116; G_loss: 0.684; D_loss_real: 2.045; D_loss_fake: 0.663; rl: 99.90%; fk: 99.32%\n",
      "20nn Classifer: \n",
      "Accuracy is 55.62%\n",
      "H 21.09%  S->T 23.88%  U->T 18.89%  \n",
      "\u001b[31mSave model to out/GBU_SUN/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_600.tar\u001b[0m\n",
      "Iter-620; Was_D: 1.361; Euc_ls: 7.376; reg_ls: 2.096; G_loss: 0.688; D_loss_real: 2.101; D_loss_fake: 0.740; rl: 99.80%; fk: 99.80%\n",
      "Iter-640; Was_D: 1.368; Euc_ls: 7.096; reg_ls: 2.076; G_loss: 0.647; D_loss_real: 2.027; D_loss_fake: 0.659; rl: 99.90%; fk: 99.71%\n",
      "20nn Classifer: \n",
      "Accuracy is 55.69%\n",
      "H 22.61%  S->T 24.92%  U->T 20.69%  \n",
      "Iter-660; Was_D: 1.360; Euc_ls: 7.030; reg_ls: 2.057; G_loss: 0.668; D_loss_real: 2.012; D_loss_fake: 0.652; rl: 99.90%; fk: 99.71%\n",
      "Iter-680; Was_D: 1.340; Euc_ls: 7.326; reg_ls: 2.037; G_loss: 0.669; D_loss_real: 2.063; D_loss_fake: 0.723; rl: 99.80%; fk: 99.71%\n",
      "20nn Classifer: \n",
      "Accuracy is 55.42%\n",
      "H 21.19%  S->T 23.68%  U->T 19.17%  \n",
      "Iter-700; Was_D: 1.325; Euc_ls: 7.240; reg_ls: 2.018; G_loss: 0.694; D_loss_real: 2.031; D_loss_fake: 0.706; rl: 99.90%; fk: 99.80%\n",
      "Iter-720; Was_D: 1.359; Euc_ls: 7.343; reg_ls: 1.999; G_loss: 0.739; D_loss_real: 2.167; D_loss_fake: 0.808; rl: 100.00%; fk: 99.51%\n",
      "20nn Classifer: \n",
      "Accuracy is 56.25%\n",
      "H 22.23%  S->T 25.47%  U->T 19.72%  \n",
      "Iter-740; Was_D: 1.343; Euc_ls: 7.278; reg_ls: 1.981; G_loss: 0.614; D_loss_real: 1.898; D_loss_fake: 0.556; rl: 100.00%; fk: 99.80%\n",
      "Iter-760; Was_D: 1.366; Euc_ls: 7.413; reg_ls: 1.962; G_loss: 0.704; D_loss_real: 2.096; D_loss_fake: 0.730; rl: 99.90%; fk: 99.41%\n",
      "20nn Classifer: \n",
      "Accuracy is 55.49%\n",
      "H 21.96%  S->T 24.77%  U->T 19.72%  \n",
      "Iter-780; Was_D: 1.343; Euc_ls: 6.954; reg_ls: 1.944; G_loss: 0.659; D_loss_real: 2.024; D_loss_fake: 0.681; rl: 100.00%; fk: 99.90%\n",
      "Iter-800; Was_D: 1.350; Euc_ls: 7.238; reg_ls: 1.926; G_loss: 0.721; D_loss_real: 2.078; D_loss_fake: 0.728; rl: 99.80%; fk: 99.51%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.64%\n",
      "H 22.03%  S->T 24.73%  U->T 19.86%  \n",
      "\u001b[31mSave model to out/GBU_SUN/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_800.tar\u001b[0m\n",
      "Iter-820; Was_D: 1.329; Euc_ls: 7.192; reg_ls: 1.908; G_loss: 0.697; D_loss_real: 2.030; D_loss_fake: 0.702; rl: 100.00%; fk: 99.80%\n",
      "Iter-840; Was_D: 1.347; Euc_ls: 7.234; reg_ls: 1.890; G_loss: 0.634; D_loss_real: 2.030; D_loss_fake: 0.683; rl: 100.00%; fk: 99.61%\n",
      "20nn Classifer: \n",
      "Accuracy is 55.83%\n",
      "H 22.85%  S->T 24.81%  U->T 21.18%  \n",
      "Iter-860; Was_D: 1.367; Euc_ls: 7.608; reg_ls: 1.872; G_loss: 0.695; D_loss_real: 2.092; D_loss_fake: 0.725; rl: 100.00%; fk: 99.80%\n",
      "Iter-880; Was_D: 1.340; Euc_ls: 7.535; reg_ls: 1.855; G_loss: 0.626; D_loss_real: 1.991; D_loss_fake: 0.651; rl: 100.00%; fk: 99.80%\n",
      "20nn Classifer: \n",
      "Accuracy is 55.76%\n",
      "H 23.05%  S->T 25.70%  U->T 20.90%  \n",
      "Iter-900; Was_D: 1.359; Euc_ls: 7.018; reg_ls: 1.838; G_loss: 0.709; D_loss_real: 2.043; D_loss_fake: 0.684; rl: 99.90%; fk: 100.00%\n",
      "Iter-920; Was_D: 1.384; Euc_ls: 7.027; reg_ls: 1.821; G_loss: 0.693; D_loss_real: 2.025; D_loss_fake: 0.641; rl: 99.80%; fk: 99.90%\n",
      "20nn Classifer: \n",
      "Accuracy is 55.83%\n",
      "H 22.33%  S->T 25.62%  U->T 19.79%  \n",
      "Iter-940; Was_D: 1.350; Euc_ls: 6.981; reg_ls: 1.804; G_loss: 0.704; D_loss_real: 2.029; D_loss_fake: 0.679; rl: 100.00%; fk: 99.90%\n",
      "Iter-960; Was_D: 1.324; Euc_ls: 7.414; reg_ls: 1.788; G_loss: 0.672; D_loss_real: 2.025; D_loss_fake: 0.702; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 56.81%\n",
      "H 22.40%  S->T 25.35%  U->T 20.07%  \n",
      "Iter-980; Was_D: 1.352; Euc_ls: 6.941; reg_ls: 1.772; G_loss: 0.653; D_loss_real: 2.023; D_loss_fake: 0.671; rl: 100.00%; fk: 100.00%\n",
      "Iter-1000; Was_D: 1.346; Euc_ls: 7.178; reg_ls: 1.755; G_loss: 0.716; D_loss_real: 2.032; D_loss_fake: 0.686; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.50%\n",
      "H 22.86%  S->T 25.85%  U->T 20.49%  \n",
      "\u001b[31mSave model to out/GBU_SUN/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_1000.tar\u001b[0m\n",
      "Iter-1020; Was_D: 1.367; Euc_ls: 7.229; reg_ls: 1.739; G_loss: 0.624; D_loss_real: 1.965; D_loss_fake: 0.599; rl: 100.00%; fk: 99.71%\n",
      "Iter-1040; Was_D: 1.365; Euc_ls: 7.214; reg_ls: 1.723; G_loss: 0.604; D_loss_real: 1.985; D_loss_fake: 0.620; rl: 99.90%; fk: 99.90%\n",
      "20nn Classifer: \n",
      "Accuracy is 56.32%\n",
      "H 22.20%  S->T 25.74%  U->T 19.51%  \n",
      "Iter-1060; Was_D: 1.359; Euc_ls: 7.162; reg_ls: 1.708; G_loss: 0.528; D_loss_real: 1.862; D_loss_fake: 0.503; rl: 100.00%; fk: 99.80%\n",
      "Iter-1080; Was_D: 1.353; Euc_ls: 7.332; reg_ls: 1.692; G_loss: 0.563; D_loss_real: 1.945; D_loss_fake: 0.592; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.01%\n",
      "H 23.42%  S->T 25.97%  U->T 21.32%  \n",
      "Iter-1100; Was_D: 1.330; Euc_ls: 7.505; reg_ls: 1.677; G_loss: 0.609; D_loss_real: 1.950; D_loss_fake: 0.620; rl: 100.00%; fk: 99.80%\n",
      "Iter-1120; Was_D: 1.323; Euc_ls: 7.297; reg_ls: 1.661; G_loss: 0.627; D_loss_real: 1.954; D_loss_fake: 0.631; rl: 100.00%; fk: 99.90%\n",
      "20nn Classifer: \n",
      "Accuracy is 56.04%\n",
      "H 22.68%  S->T 25.50%  U->T 20.42%  \n",
      "Iter-1140; Was_D: 1.358; Euc_ls: 7.301; reg_ls: 1.646; G_loss: 0.606; D_loss_real: 1.971; D_loss_fake: 0.613; rl: 100.00%; fk: 100.00%\n",
      "Iter-1160; Was_D: 1.348; Euc_ls: 7.368; reg_ls: 1.631; G_loss: 0.573; D_loss_real: 1.923; D_loss_fake: 0.574; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.01%\n",
      "H 23.10%  S->T 26.71%  U->T 20.35%  \n",
      "Iter-1180; Was_D: 1.342; Euc_ls: 7.176; reg_ls: 1.617; G_loss: 0.480; D_loss_real: 1.879; D_loss_fake: 0.538; rl: 100.00%; fk: 99.90%\n",
      "Iter-1200; Was_D: 1.373; Euc_ls: 7.265; reg_ls: 1.602; G_loss: 0.561; D_loss_real: 1.978; D_loss_fake: 0.605; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 56.39%\n",
      "H 23.45%  S->T 26.05%  U->T 21.32%  \n",
      "\u001b[31mSave model to out/GBU_SUN/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_1200.tar\u001b[0m\n",
      "Iter-1220; Was_D: 1.364; Euc_ls: 6.887; reg_ls: 1.588; G_loss: 0.518; D_loss_real: 1.859; D_loss_fake: 0.496; rl: 100.00%; fk: 99.90%\n",
      "Iter-1240; Was_D: 1.414; Euc_ls: 7.435; reg_ls: 1.573; G_loss: 0.590; D_loss_real: 1.987; D_loss_fake: 0.574; rl: 100.00%; fk: 99.90%\n",
      "20nn Classifer: \n",
      "Accuracy is 56.81%\n",
      "H 22.96%  S->T 26.01%  U->T 20.56%  \n",
      "Iter-1260; Was_D: 1.354; Euc_ls: 6.998; reg_ls: 1.559; G_loss: 0.504; D_loss_real: 1.884; D_loss_fake: 0.530; rl: 100.00%; fk: 100.00%\n",
      "Iter-1280; Was_D: 1.385; Euc_ls: 7.089; reg_ls: 1.545; G_loss: 0.524; D_loss_real: 1.873; D_loss_fake: 0.487; rl: 100.00%; fk: 99.80%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.15%\n",
      "H 23.31%  S->T 26.24%  U->T 20.97%  \n",
      "Iter-1300; Was_D: 1.374; Euc_ls: 7.153; reg_ls: 1.531; G_loss: 0.515; D_loss_real: 1.891; D_loss_fake: 0.517; rl: 100.00%; fk: 99.71%\n",
      "Iter-1320; Was_D: 1.385; Euc_ls: 7.329; reg_ls: 1.517; G_loss: 0.469; D_loss_real: 1.853; D_loss_fake: 0.467; rl: 100.00%; fk: 99.80%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.43%\n",
      "H 22.86%  S->T 26.20%  U->T 20.28%  \n",
      "Iter-1340; Was_D: 1.362; Euc_ls: 7.195; reg_ls: 1.504; G_loss: 0.460; D_loss_real: 1.833; D_loss_fake: 0.471; rl: 100.00%; fk: 100.00%\n",
      "Iter-1360; Was_D: 1.386; Euc_ls: 7.185; reg_ls: 1.490; G_loss: 0.440; D_loss_real: 1.795; D_loss_fake: 0.409; rl: 99.90%; fk: 99.80%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.29%\n",
      "H 22.95%  S->T 25.35%  U->T 20.97%  \n",
      "Iter-1380; Was_D: 1.381; Euc_ls: 7.330; reg_ls: 1.477; G_loss: 0.449; D_loss_real: 1.854; D_loss_fake: 0.473; rl: 100.00%; fk: 100.00%\n",
      "Iter-1400; Was_D: 1.413; Euc_ls: 7.047; reg_ls: 1.464; G_loss: 0.442; D_loss_real: 1.846; D_loss_fake: 0.432; rl: 100.00%; fk: 99.80%\n",
      "20nn Classifer: \n",
      "Accuracy is 56.88%\n",
      "H 22.85%  S->T 25.93%  U->T 20.42%  \n",
      "\u001b[31mSave model to out/GBU_SUN/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_1400.tar\u001b[0m\n",
      "Iter-1420; Was_D: 1.391; Euc_ls: 7.375; reg_ls: 1.451; G_loss: 0.533; D_loss_real: 1.908; D_loss_fake: 0.517; rl: 100.00%; fk: 99.80%\n",
      "Iter-1440; Was_D: 1.404; Euc_ls: 7.262; reg_ls: 1.438; G_loss: 0.384; D_loss_real: 1.809; D_loss_fake: 0.404; rl: 100.00%; fk: 99.80%\n",
      "20nn Classifer: \n",
      "Accuracy is 56.67%\n",
      "H 22.80%  S->T 25.81%  U->T 20.42%  \n",
      "Iter-1460; Was_D: 1.395; Euc_ls: 7.033; reg_ls: 1.425; G_loss: 0.446; D_loss_real: 1.845; D_loss_fake: 0.450; rl: 100.00%; fk: 100.00%\n",
      "Iter-1480; Was_D: 1.404; Euc_ls: 7.165; reg_ls: 1.413; G_loss: 0.401; D_loss_real: 1.816; D_loss_fake: 0.412; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.36%\n",
      "H 23.30%  S->T 26.43%  U->T 20.83%  \n",
      "Iter-1500; Was_D: 1.379; Euc_ls: 7.264; reg_ls: 1.400; G_loss: 0.336; D_loss_real: 1.737; D_loss_fake: 0.358; rl: 100.00%; fk: 100.00%\n",
      "Iter-1520; Was_D: 1.415; Euc_ls: 7.012; reg_ls: 1.388; G_loss: 0.380; D_loss_real: 1.854; D_loss_fake: 0.439; rl: 100.00%; fk: 99.80%\n",
      "20nn Classifer: \n",
      "Accuracy is 56.94%\n",
      "H 22.79%  S->T 26.24%  U->T 20.14%  \n",
      "Iter-1540; Was_D: 1.424; Euc_ls: 7.013; reg_ls: 1.376; G_loss: 0.360; D_loss_real: 1.783; D_loss_fake: 0.359; rl: 100.00%; fk: 99.90%\n",
      "Iter-1560; Was_D: 1.417; Euc_ls: 7.108; reg_ls: 1.364; G_loss: 0.414; D_loss_real: 1.833; D_loss_fake: 0.416; rl: 100.00%; fk: 99.80%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.26%\n",
      "H 23.98%  S->T 26.63%  U->T 21.81%  \n",
      "Iter-1580; Was_D: 1.423; Euc_ls: 6.943; reg_ls: 1.353; G_loss: 0.320; D_loss_real: 1.783; D_loss_fake: 0.360; rl: 100.00%; fk: 99.80%\n",
      "Iter-1600; Was_D: 1.399; Euc_ls: 7.161; reg_ls: 1.341; G_loss: 0.350; D_loss_real: 1.765; D_loss_fake: 0.366; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.78%\n",
      "H 24.07%  S->T 27.17%  U->T 21.60%  \n",
      "\u001b[31mSave model to out/GBU_SUN/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_1600.tar\u001b[0m\n",
      "Iter-1620; Was_D: 1.446; Euc_ls: 7.102; reg_ls: 1.331; G_loss: 0.346; D_loss_real: 1.785; D_loss_fake: 0.340; rl: 100.00%; fk: 100.00%\n",
      "Iter-1640; Was_D: 1.439; Euc_ls: 7.131; reg_ls: 1.320; G_loss: 0.303; D_loss_real: 1.779; D_loss_fake: 0.340; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.43%\n",
      "H 23.98%  S->T 27.64%  U->T 21.18%  \n",
      "Iter-1660; Was_D: 1.446; Euc_ls: 7.210; reg_ls: 1.309; G_loss: 0.253; D_loss_real: 1.682; D_loss_fake: 0.236; rl: 100.00%; fk: 100.00%\n",
      "Iter-1680; Was_D: 1.456; Euc_ls: 7.314; reg_ls: 1.298; G_loss: 0.337; D_loss_real: 1.806; D_loss_fake: 0.349; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.78%\n",
      "H 23.65%  S->T 27.71%  U->T 20.62%  \n",
      "Iter-1700; Was_D: 1.465; Euc_ls: 7.282; reg_ls: 1.288; G_loss: 0.311; D_loss_real: 1.807; D_loss_fake: 0.342; rl: 100.00%; fk: 100.00%\n",
      "Iter-1720; Was_D: 1.472; Euc_ls: 7.145; reg_ls: 1.278; G_loss: 0.369; D_loss_real: 1.866; D_loss_fake: 0.394; rl: 100.00%; fk: 99.90%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.85%\n",
      "H 24.00%  S->T 27.33%  U->T 21.39%  \n",
      "Iter-1740; Was_D: 1.470; Euc_ls: 7.057; reg_ls: 1.268; G_loss: 0.194; D_loss_real: 1.677; D_loss_fake: 0.207; rl: 100.00%; fk: 99.90%\n",
      "Iter-1760; Was_D: 1.476; Euc_ls: 7.111; reg_ls: 1.258; G_loss: 0.267; D_loss_real: 1.729; D_loss_fake: 0.252; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 56.46%\n",
      "H 24.07%  S->T 27.40%  U->T 21.46%  \n",
      "Iter-1780; Was_D: 1.449; Euc_ls: 6.982; reg_ls: 1.248; G_loss: 0.244; D_loss_real: 1.700; D_loss_fake: 0.251; rl: 99.90%; fk: 100.00%\n",
      "Iter-1800; Was_D: 1.453; Euc_ls: 7.157; reg_ls: 1.239; G_loss: 0.342; D_loss_real: 1.839; D_loss_fake: 0.386; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.15%\n",
      "H 23.46%  S->T 27.83%  U->T 20.28%  \n",
      "\u001b[31mSave model to out/GBU_SUN/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_1800.tar\u001b[0m\n",
      "Iter-1820; Was_D: 1.490; Euc_ls: 7.065; reg_ls: 1.230; G_loss: 0.399; D_loss_real: 1.856; D_loss_fake: 0.366; rl: 100.00%; fk: 100.00%\n",
      "Iter-1840; Was_D: 1.452; Euc_ls: 7.229; reg_ls: 1.221; G_loss: 0.324; D_loss_real: 1.802; D_loss_fake: 0.350; rl: 100.00%; fk: 99.90%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.01%\n",
      "H 24.61%  S->T 27.79%  U->T 22.08%  \n",
      "Iter-1860; Was_D: 1.494; Euc_ls: 7.206; reg_ls: 1.212; G_loss: 0.203; D_loss_real: 1.755; D_loss_fake: 0.261; rl: 100.00%; fk: 100.00%\n",
      "Iter-1880; Was_D: 1.471; Euc_ls: 6.939; reg_ls: 1.203; G_loss: 0.297; D_loss_real: 1.804; D_loss_fake: 0.333; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.29%\n",
      "H 23.20%  S->T 26.63%  U->T 20.56%  \n",
      "Iter-1900; Was_D: 1.507; Euc_ls: 7.067; reg_ls: 1.195; G_loss: 0.252; D_loss_real: 1.758; D_loss_fake: 0.251; rl: 100.00%; fk: 100.00%\n",
      "Iter-1920; Was_D: 1.484; Euc_ls: 7.109; reg_ls: 1.186; G_loss: 0.380; D_loss_real: 1.869; D_loss_fake: 0.385; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.57%\n",
      "H 23.50%  S->T 27.95%  U->T 20.28%  \n",
      "Iter-1940; Was_D: 1.498; Euc_ls: 7.039; reg_ls: 1.179; G_loss: 0.255; D_loss_real: 1.725; D_loss_fake: 0.227; rl: 100.00%; fk: 99.90%\n",
      "Iter-1960; Was_D: 1.486; Euc_ls: 7.275; reg_ls: 1.171; G_loss: 0.289; D_loss_real: 1.772; D_loss_fake: 0.286; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.47%\n",
      "H 23.51%  S->T 27.33%  U->T 20.62%  \n",
      "Iter-1980; Was_D: 1.495; Euc_ls: 6.935; reg_ls: 1.164; G_loss: 0.338; D_loss_real: 1.825; D_loss_fake: 0.330; rl: 100.00%; fk: 100.00%\n",
      "Iter-2000; Was_D: 1.503; Euc_ls: 7.030; reg_ls: 1.156; G_loss: 0.320; D_loss_real: 1.798; D_loss_fake: 0.295; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 56.94%\n",
      "H 23.34%  S->T 27.25%  U->T 20.42%  \n",
      "\u001b[31mSave model to out/GBU_SUN/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_2000.tar\u001b[0m\n",
      "Iter-2020; Was_D: 1.497; Euc_ls: 6.894; reg_ls: 1.149; G_loss: 0.236; D_loss_real: 1.711; D_loss_fake: 0.214; rl: 99.90%; fk: 100.00%\n",
      "Iter-2040; Was_D: 1.532; Euc_ls: 7.095; reg_ls: 1.143; G_loss: 0.172; D_loss_real: 1.745; D_loss_fake: 0.213; rl: 100.00%; fk: 99.80%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.85%\n",
      "H 24.01%  S->T 26.82%  U->T 21.74%  \n",
      "Iter-2060; Was_D: 1.543; Euc_ls: 7.125; reg_ls: 1.136; G_loss: 0.363; D_loss_real: 1.938; D_loss_fake: 0.395; rl: 100.00%; fk: 99.90%\n",
      "Iter-2080; Was_D: 1.521; Euc_ls: 7.052; reg_ls: 1.129; G_loss: 0.325; D_loss_real: 1.875; D_loss_fake: 0.354; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.36%\n",
      "H 23.57%  S->T 27.25%  U->T 20.76%  \n",
      "Iter-2100; Was_D: 1.515; Euc_ls: 7.129; reg_ls: 1.123; G_loss: 0.214; D_loss_real: 1.774; D_loss_fake: 0.259; rl: 100.00%; fk: 100.00%\n",
      "Iter-2120; Was_D: 1.524; Euc_ls: 7.158; reg_ls: 1.117; G_loss: 0.191; D_loss_real: 1.707; D_loss_fake: 0.184; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.33%\n",
      "H 23.83%  S->T 26.90%  U->T 21.39%  \n",
      "Iter-2140; Was_D: 1.512; Euc_ls: 7.027; reg_ls: 1.111; G_loss: 0.212; D_loss_real: 1.750; D_loss_fake: 0.238; rl: 100.00%; fk: 100.00%\n",
      "Iter-2160; Was_D: 1.514; Euc_ls: 7.141; reg_ls: 1.104; G_loss: 0.431; D_loss_real: 1.977; D_loss_fake: 0.463; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.61%\n",
      "H 24.04%  S->T 27.56%  U->T 21.32%  \n",
      "Iter-2180; Was_D: 1.566; Euc_ls: 6.975; reg_ls: 1.099; G_loss: 0.154; D_loss_real: 1.766; D_loss_fake: 0.201; rl: 99.90%; fk: 100.00%\n",
      "Iter-2200; Was_D: 1.509; Euc_ls: 7.355; reg_ls: 1.093; G_loss: 0.291; D_loss_real: 1.787; D_loss_fake: 0.278; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 56.74%\n",
      "H 22.39%  S->T 26.51%  U->T 19.37%  \n",
      "\u001b[31mSave model to out/GBU_SUN/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_2200.tar\u001b[0m\n",
      "Iter-2220; Was_D: 1.551; Euc_ls: 7.003; reg_ls: 1.087; G_loss: 0.204; D_loss_real: 1.786; D_loss_fake: 0.235; rl: 100.00%; fk: 100.00%\n",
      "Iter-2240; Was_D: 1.530; Euc_ls: 7.062; reg_ls: 1.082; G_loss: 0.179; D_loss_real: 1.777; D_loss_fake: 0.247; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.43%\n",
      "H 23.71%  S->T 26.09%  U->T 21.74%  \n",
      "Iter-2260; Was_D: 1.560; Euc_ls: 7.154; reg_ls: 1.077; G_loss: 0.467; D_loss_real: 2.059; D_loss_fake: 0.499; rl: 99.90%; fk: 100.00%\n",
      "Iter-2280; Was_D: 1.592; Euc_ls: 7.162; reg_ls: 1.072; G_loss: 0.339; D_loss_real: 1.971; D_loss_fake: 0.379; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.06%\n",
      "H 23.50%  S->T 27.56%  U->T 20.49%  \n",
      "Iter-2300; Was_D: 1.570; Euc_ls: 6.989; reg_ls: 1.066; G_loss: 0.330; D_loss_real: 1.903; D_loss_fake: 0.333; rl: 100.00%; fk: 100.00%\n",
      "Iter-2320; Was_D: 1.547; Euc_ls: 7.184; reg_ls: 1.062; G_loss: 0.333; D_loss_real: 1.893; D_loss_fake: 0.346; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.43%\n",
      "H 23.55%  S->T 27.83%  U->T 20.42%  \n",
      "Iter-2340; Was_D: 1.549; Euc_ls: 6.987; reg_ls: 1.057; G_loss: 0.151; D_loss_real: 1.746; D_loss_fake: 0.197; rl: 100.00%; fk: 99.90%\n",
      "Iter-2360; Was_D: 1.580; Euc_ls: 7.380; reg_ls: 1.052; G_loss: 0.150; D_loss_real: 1.760; D_loss_fake: 0.180; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.64%\n",
      "H 23.35%  S->T 26.67%  U->T 20.76%  \n",
      "Iter-2380; Was_D: 1.594; Euc_ls: 7.212; reg_ls: 1.048; G_loss: 0.369; D_loss_real: 1.929; D_loss_fake: 0.335; rl: 100.00%; fk: 100.00%\n",
      "Iter-2400; Was_D: 1.563; Euc_ls: 7.198; reg_ls: 1.043; G_loss: 0.288; D_loss_real: 1.868; D_loss_fake: 0.305; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.64%\n",
      "H 24.29%  S->T 27.40%  U->T 21.81%  \n",
      "\u001b[31mSave model to out/GBU_SUN/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_2400.tar\u001b[0m\n",
      "Iter-2420; Was_D: 1.533; Euc_ls: 7.080; reg_ls: 1.039; G_loss: 0.286; D_loss_real: 1.861; D_loss_fake: 0.327; rl: 100.00%; fk: 100.00%\n",
      "Iter-2440; Was_D: 1.580; Euc_ls: 7.044; reg_ls: 1.035; G_loss: 0.166; D_loss_real: 1.762; D_loss_fake: 0.182; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 56.60%\n",
      "H 23.82%  S->T 26.98%  U->T 21.32%  \n",
      "Iter-2460; Was_D: 1.580; Euc_ls: 6.901; reg_ls: 1.031; G_loss: 0.318; D_loss_real: 1.902; D_loss_fake: 0.322; rl: 100.00%; fk: 100.00%\n",
      "Iter-2480; Was_D: 1.613; Euc_ls: 7.026; reg_ls: 1.027; G_loss: 0.343; D_loss_real: 1.987; D_loss_fake: 0.375; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.43%\n",
      "H 23.76%  S->T 28.02%  U->T 20.62%  \n",
      "Iter-2500; Was_D: 1.574; Euc_ls: 7.290; reg_ls: 1.023; G_loss: 0.437; D_loss_real: 2.058; D_loss_fake: 0.484; rl: 100.00%; fk: 100.00%\n",
      "Iter-2520; Was_D: 1.586; Euc_ls: 6.954; reg_ls: 1.019; G_loss: 0.204; D_loss_real: 1.873; D_loss_fake: 0.287; rl: 100.00%; fk: 99.90%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.57%\n",
      "H 22.96%  S->T 26.94%  U->T 20.00%  \n",
      "Iter-2540; Was_D: 1.573; Euc_ls: 7.198; reg_ls: 1.016; G_loss: 0.279; D_loss_real: 1.894; D_loss_fake: 0.320; rl: 100.00%; fk: 100.00%\n",
      "Iter-2560; Was_D: 1.590; Euc_ls: 7.011; reg_ls: 1.012; G_loss: 0.387; D_loss_real: 2.031; D_loss_fake: 0.441; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.26%\n",
      "H 23.37%  S->T 27.33%  U->T 20.42%  \n",
      "Iter-2580; Was_D: 1.593; Euc_ls: 7.455; reg_ls: 1.008; G_loss: 0.488; D_loss_real: 2.111; D_loss_fake: 0.518; rl: 100.00%; fk: 100.00%\n",
      "Iter-2600; Was_D: 1.609; Euc_ls: 6.852; reg_ls: 1.005; G_loss: 0.298; D_loss_real: 1.924; D_loss_fake: 0.315; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.19%\n",
      "H 23.50%  S->T 27.05%  U->T 20.76%  \n",
      "\u001b[31mSave model to out/GBU_SUN/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_2600.tar\u001b[0m\n",
      "Iter-2620; Was_D: 1.611; Euc_ls: 7.218; reg_ls: 1.001; G_loss: 0.383; D_loss_real: 2.002; D_loss_fake: 0.391; rl: 100.00%; fk: 100.00%\n",
      "Iter-2640; Was_D: 1.562; Euc_ls: 7.066; reg_ls: 0.998; G_loss: 0.411; D_loss_real: 1.979; D_loss_fake: 0.417; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 56.46%\n",
      "H 22.77%  S->T 28.33%  U->T 19.03%  \n",
      "Iter-2660; Was_D: 1.616; Euc_ls: 7.193; reg_ls: 0.994; G_loss: 0.530; D_loss_real: 2.155; D_loss_fake: 0.538; rl: 100.00%; fk: 100.00%\n",
      "Iter-2680; Was_D: 1.632; Euc_ls: 7.011; reg_ls: 0.991; G_loss: 0.363; D_loss_real: 1.991; D_loss_fake: 0.359; rl: 99.90%; fk: 99.90%\n",
      "20nn Classifer: \n",
      "Accuracy is 58.33%\n",
      "H 22.69%  S->T 27.95%  U->T 19.10%  \n",
      "Iter-2700; Was_D: 1.583; Euc_ls: 7.271; reg_ls: 0.987; G_loss: 0.373; D_loss_real: 2.026; D_loss_fake: 0.442; rl: 100.00%; fk: 100.00%\n",
      "Iter-2720; Was_D: 1.612; Euc_ls: 7.220; reg_ls: 0.984; G_loss: 0.368; D_loss_real: 1.967; D_loss_fake: 0.355; rl: 99.90%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.50%\n",
      "H 22.16%  S->T 27.67%  U->T 18.47%  \n",
      "Iter-2740; Was_D: 1.624; Euc_ls: 7.111; reg_ls: 0.981; G_loss: 0.491; D_loss_real: 2.117; D_loss_fake: 0.493; rl: 100.00%; fk: 100.00%\n",
      "Iter-2760; Was_D: 1.608; Euc_ls: 7.089; reg_ls: 0.978; G_loss: 0.361; D_loss_real: 2.004; D_loss_fake: 0.396; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 56.88%\n",
      "H 23.15%  S->T 27.48%  U->T 20.00%  \n",
      "Iter-2780; Was_D: 1.631; Euc_ls: 7.204; reg_ls: 0.975; G_loss: 0.283; D_loss_real: 1.913; D_loss_fake: 0.282; rl: 100.00%; fk: 100.00%\n",
      "Iter-2800; Was_D: 1.607; Euc_ls: 6.971; reg_ls: 0.972; G_loss: 0.401; D_loss_real: 2.034; D_loss_fake: 0.428; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.29%\n",
      "H 22.98%  S->T 28.53%  U->T 19.24%  \n",
      "\u001b[31mSave model to out/GBU_SUN/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_2800.tar\u001b[0m\n",
      "Iter-2820; Was_D: 1.636; Euc_ls: 6.940; reg_ls: 0.969; G_loss: 0.407; D_loss_real: 2.029; D_loss_fake: 0.394; rl: 100.00%; fk: 100.00%\n",
      "Iter-2840; Was_D: 1.598; Euc_ls: 6.815; reg_ls: 0.966; G_loss: 0.440; D_loss_real: 2.099; D_loss_fake: 0.500; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.15%\n",
      "H 23.18%  S->T 28.10%  U->T 19.72%  \n",
      "Iter-2860; Was_D: 1.634; Euc_ls: 6.914; reg_ls: 0.963; G_loss: 0.225; D_loss_real: 1.877; D_loss_fake: 0.243; rl: 100.00%; fk: 99.90%\n",
      "Iter-2880; Was_D: 1.608; Euc_ls: 7.035; reg_ls: 0.960; G_loss: 0.291; D_loss_real: 1.932; D_loss_fake: 0.324; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 56.67%\n",
      "H 22.68%  S->T 27.21%  U->T 19.44%  \n",
      "Iter-2900; Was_D: 1.608; Euc_ls: 7.054; reg_ls: 0.957; G_loss: 0.323; D_loss_real: 1.934; D_loss_fake: 0.326; rl: 99.90%; fk: 99.90%\n",
      "Iter-2920; Was_D: 1.629; Euc_ls: 7.141; reg_ls: 0.955; G_loss: 0.318; D_loss_real: 1.918; D_loss_fake: 0.290; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.08%\n",
      "H 23.18%  S->T 27.44%  U->T 20.07%  \n",
      "Iter-2940; Was_D: 1.659; Euc_ls: 6.979; reg_ls: 0.952; G_loss: 0.476; D_loss_real: 2.128; D_loss_fake: 0.470; rl: 100.00%; fk: 100.00%\n",
      "Iter-2960; Was_D: 1.639; Euc_ls: 7.303; reg_ls: 0.949; G_loss: 0.340; D_loss_real: 1.926; D_loss_fake: 0.288; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 57.22%\n",
      "H 22.50%  S->T 27.98%  U->T 18.82%  \n",
      "Iter-2980; Was_D: 1.630; Euc_ls: 7.058; reg_ls: 0.947; G_loss: 0.294; D_loss_real: 1.975; D_loss_fake: 0.345; rl: 100.00%; fk: 100.00%\n",
      "Iter-3000; Was_D: 1.644; Euc_ls: 7.058; reg_ls: 0.944; G_loss: 0.225; D_loss_real: 1.880; D_loss_fake: 0.236; rl: 100.00%; fk: 100.00%\n",
      "20nn Classifer: \n",
      "Accuracy is 55.69%\n",
      "H 22.51%  S->T 26.98%  U->T 19.31%  \n",
      "\u001b[31mSave model to out/GBU_SUN/Model_2_CAN0.1_Eu5_Rls0.001_RWz0_Reproduce/Iter_3000.tar\u001b[0m\n",
      "===============\n",
      "===============\n",
      "Reproduce SUN\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/camaral/code/gans_course/hw5/ZSL_GAN/train_GBU_CIZSL.py\", line 664, in <module>\n",
      "    print(\"Accuracy is {:.4}%, and Generalized AUC is {:.4}%\".format(result.best_acc, result.best_auc))\n",
      "AttributeError: 'NoneType' object has no attribute 'best_acc'\n",
      "/home/camaral/code/gans_course/hw5\n"
     ]
    }
   ],
   "source": [
    "%cd ZSL_GAN\n",
    "!python train_GBU_CIZSL.py --dataset 'SUN' --preprocessing --z_dim 10 --creativity_weight 0.1\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5defa01c-11ec-4386-95ce-e19c79e1390a",
   "metadata": {},
   "source": [
    "- (Bonus Point.) (20pt) Replace the original text features with the one extracted from CLIP [3]. (Hint. You only need to get the text features from CLIP instead of re-training it.)\n",
    "\n",
    "I could not implement this properly due to the lack of documentation on how the dataset stores the attributes. My idea was to:\n",
    "\n",
    "- Get attributes for each image (e.g. has orange beak, has purple breast)\n",
    "- Merge all attributes together in a string (\"A bird that has orange beak and has purple breast\")\n",
    "- Tokenize the strings using CLIP: `import clip; token = clip.tokenize(string_batch)`\n",
    "- Encode token using CLIP: `model = clip.load('ViT-B/32', device=torch.device(\"cuda\"); text_feats = model.encode_text(token)` \n",
    "\n",
    "Now we can pass the text features to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daef28b-99c4-4c13-9950-d284b8ba927c",
   "metadata": {},
   "source": [
    "### 2. Score-Based Generative Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478015f1-65ed-4b34-8d64-7b9110c4698d",
   "metadata": {},
   "source": [
    "2.1 Basic Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0553188e-5e07-432a-a012-7f6dd2802ad1",
   "metadata": {},
   "source": [
    "- <strong>Describe the pipeline logic of [4] (i.e., forward and backward steps).</strong>\n",
    "\n",
    "The forward process consists of a diffusion process, a Stochastic Differential Equation (SDE), that adds noise to the data distribution ($p_0(x)$) slowly, a bit in each layer, up to the last layer ($p_T(x)$) where the distribution is just noise and no more of the original data is left.\n",
    "\n",
    "The diffusion process can be reversed by applying another diffusion process that can be obtained by estimating the score: $\\nabla_x log\\,p_t(x), t \\in \\left[ 0,T\\right]$. The score estimate $s_\\theta(x(t),t)$ is learned during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622f27f9-03b9-4057-806c-d90c228fd684",
   "metadata": {},
   "source": [
    "- <strong>What is Energy-Based Models (EBMs) and Score-Based Generative Models (SBGMs)?</strong>\n",
    "\n",
    "Energy-based models are those that model a data distribution in the form:\n",
    "\n",
    "$$ p_\\theta(x) = \\frac{e^{-E_\\theta(x)}}{Z_\\theta},\\;\\text{where: } Z_\\theta = \\int e^{-E_\\theta(x)} dx$$\n",
    "\n",
    "$Z_\\theta$ is not tractable as it involves computing an integral over all dimensions of the data, thus the usual way to go is to compute $\\nabla_\\theta log\\,p_\\theta(x) = - \\nabla_\\theta E_\\theta(x) + \\mathbb{E}_{x\\sim p_\\theta(x)}\\left[\\nabla_\\theta E_\\theta(x) \\right]$ and use gradient ascent to maximize the log-likelihood of $E_\\theta(x)$ given a dataset.\n",
    "\n",
    "However, even if a model for the distribution is given, it still is hard to sample from it. Score-based sampling techniques such as Langevin MCMC estimate the score $\\nabla_x log\\,p_t(x)$ and use it to sample from a data distribution without the need to estimate the data distribution itself. Methods that use score-based sampling for generating data that is similar to prior dataset are called Score-Based Generative Models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34807e97-d690-44ef-a66c-3b08b9a9d2d1",
   "metadata": {},
   "source": [
    "- <strong>What is the difference among Euler-Maruyama sampling, Langevin MCMC sampling, and Predictor-Corrector (PC) sampling?</strong>\n",
    "\n",
    "The Euler-Maruyama sampling method applies the Euler-Maruyama SDE solver to come up with a solution for the reverse diffusion model (that takes a sample from the prior to the data distribution), which means generating a new sample given a sample from the prior.\n",
    "\n",
    "The Langevin MCMC method generates samples by iterating over the equation:\n",
    "\n",
    "$$x_i^m = x_i^{m-1} + \\varepsilon_i s_\\theta (x_i^{m-1}, \\sigma_i) + \\sqrt{2 \\varepsilon_i} z_i^m,\\quad m=1,2,3,\\dots,M$$\n",
    "\n",
    "It starts from $x_i$ and iterates over it until reaching at the final generated sample: $x_i^M$.\n",
    "\n",
    "The Predictor-Corrector (PC) class of samplers generalize over the past 2 methods: the Predictor can be any SDE solver (e.g. Euler-Maruyama) and the Corrector can be any score-based MCMC approach (e.g. Langevin MCMC). The proposed PC samplers are tailored for reverse diffusion sampling, where they perform better than the previously mentioned techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c597b8-6d5d-403d-9ff8-c9016422b95a",
   "metadata": {},
   "source": [
    "- <strong>What is the difference among VE SDE, VP SDE, and sub-VP SDE?</strong>\n",
    "\n",
    "Variance Exploding (VE) SDE: The continuous-time version of the perturbation kernels used in SMLD. It is called variance exploding because it shows such property as $t\\to \\infty$. It is given by:\n",
    "\n",
    "$$ dx = \\sqrt{\\frac{d\\left[\\sigma^2(t)\\right]}{dt}} dw $$\n",
    "\n",
    "Variance Preserving (VP) SDE: The continuous-time version of the perturbation kernels used in DDPM. It is called variance preserving as its variance is always one provided the initial distribution also has unit variance. It is given by:\n",
    "\n",
    "$$ dx = -\\frac{1}{2}\\beta(t)x\\,dt + \\sqrt{\\beta(t)}dw $$\n",
    "\n",
    "Sub-VP SDE: A new type of SDEs proposed by the authors, that has the property of having its variance always bounded by the VP-SDE at every intermediate step. It is given by:\n",
    "\n",
    "$$ dx = -\\frac{1}{2}\\beta(t)x\\,dt + \\sqrt{\\beta(t)\\left(1-e^{-2\\int_0^t \\beta(s)ds}\\right)}dw $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466589aa-df01-4878-b4ec-61e4f449e225",
   "metadata": {},
   "source": [
    "- <strong>How and why SDE is connected with SBGMs?</strong>\n",
    "\n",
    "Since the transformation from data distribution to prior distribution can be modelled as a diffusion model, the reverse is also a diffusion model. As diffusion models are SDEs, they can be solved using regular SDE solvers (e.g. Euler-Maruyama), including score-based ones (e.g. Langevin MCMC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15c5277-6bd9-421f-936e-83d105f73c74",
   "metadata": {},
   "source": [
    "- <strong>How the likelihood is computed in probabilistic flow ODE? Why this can not be done for normal SDE?</strong>\n",
    "\n",
    "For any diffusion process (SDE), there exists a deterministic process (ODE) with the same marginal distribution, called the probabilistic flow ODE. It is given by:\n",
    "\n",
    "$$ \\text{log}\\,p_0(x(0)) = \\text{log}\\,p_T(x(T))+\\int\\limits_0^T \\nabla\\cdot \\mathbf{\\tilde{f_\\theta}}(\\mathbf{x}(t),t) dt $$\n",
    "\n",
    "We note that:\n",
    "\n",
    "$$\\nabla\\cdot \\mathbf{\\tilde{f_\\theta}}(\\mathbf{x},t) = \\mathbb{E}_{p(\\varepsilon)}\\left[ \\varepsilon^T \\nabla\\mathbf{\\tilde{f_\\theta}}(\\mathbf{x},t) \\varepsilon \\right] $$\n",
    "\n",
    "The term $\\varepsilon^T \\nabla\\mathbf{\\tilde{f_\\theta}}(\\mathbf{x},t)$ can be computed using automatic differentiation (available in most deep learning packages), which in turn enables the exact computation of the likelihood of data: $\\text{log}\\,p_0(x(0))$.\n",
    "\n",
    "Doing the same without translating the SDE into a probabilistic flow ODE is computationally expensive (Maximum Likelihood Estimation), and other methods focus on the use of sampling techniques (e.g. Langevin MCMC) to get samples of the data distribution, without ever estimating the likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010246d3-4bed-4b19-956b-db919b89bb0c",
   "metadata": {},
   "source": [
    "- <strong>Clarify potential disadvantages of discrete noisy perturbation (Hint, suggest reading [5].)</strong>\n",
    "\n",
    "The ideal case would be to have infinitely many noise cases, which lead to a continuous-time SDE, which then can be transformed into a probabilistic flow ODE, allowing for:\n",
    "\n",
    "- Exact likelihood computation (as shown in the previous item)\n",
    "- Faster sampling\n",
    "- Uniquely identifiable representations\n",
    "\n",
    "When using finitely-many noise perturbations the ODE is approximately equivalent, but not exactly, which lead to having no guarantees of achieving the aforementioned qualities. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f3f26a-9911-485b-8fd9-bb5380ae23e5",
   "metadata": {},
   "source": [
    "2.2 Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbbc3d2-7ddc-4594-9014-e66de9264b41",
   "metadata": {},
   "source": [
    "- <strong>You are required to generate images by using Euler Maruyama sampling strategy. You need to fill in all the TODOs in the given .ipynb. You may check the tutorial here.</strong>\n",
    "\n",
    "Please check the implementation below; full code is available on \"Tutorial_on_Score_Based_Generative_Modeling_(PyTorch).ipynb\". Code was thoroughly commented to prove understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeb1643-5be4-47ad-8c95-4b54ef201c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps =  500#@param {'type':'integer'}\n",
    "def Euler_Maruyama_sampler(score_model, \n",
    "                           marginal_prob_std,\n",
    "                           diffusion_coeff, \n",
    "                           batch_size=64, \n",
    "                           num_steps=num_steps, \n",
    "                           device='cuda', \n",
    "                           eps=1e-3):\n",
    "  \"\"\"Generate samples from score-based models with the Euler-Maruyama solver.\n",
    "\n",
    "  Args:\n",
    "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
    "    marginal_prob_std: A function that gives the standard deviation of\n",
    "      the perturbation kernel.\n",
    "    diffusion_coeff: A function that gives the diffusion coefficient of the SDE.\n",
    "    batch_size: The number of samplers to generate by calling this function once.\n",
    "    num_steps: The number of sampling steps. \n",
    "      Equivalent to the number of discretized time steps.\n",
    "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
    "    eps: The smallest time step for numerical stability.\n",
    "  \n",
    "  Returns:\n",
    "    Samples.    \n",
    "  \"\"\"\n",
    "\n",
    "  # We start by sampling z_T from our prior: N(0,I)\n",
    "  z_shape = (batch_size, 1, 28, 28)\n",
    "  z = torch.randn(*z_shape, device=device)\n",
    "  # Then we multiply it by the std. deviation (given by marginal_prob_std)\n",
    "  # T=1 (last possible time, as 0 <= t <= 1)\n",
    "  t = torch.ones(*z_shape, device=device)\n",
    "  x = z*marginal_prob_std(t)\n",
    "  # x now stores samples from the prior distribution\n",
    "\n",
    "  # Compute values of timesteps given num_steps and eps\n",
    "  steps = torch.linspace(1., eps, num_steps, device=device)\n",
    "  step_size = steps[0]-steps[1]\n",
    "    \n",
    "  # Now we run the Euler-Maruyama method for each timestep\n",
    "  with torch.no_grad():\n",
    "    for ts in tqdm.notebook.tqdm(steps):\n",
    "      # Current t\n",
    "      bts = ts*torch.ones(*z_shape, device=device)\n",
    "      g = diffusion_coeff(bts)\n",
    "      # Sample more noise\n",
    "      z = torch.randn(*z_shape, device=device)\n",
    "      # Execute Euler-Maruyama method\n",
    "      x = x + step_size*(g**2)*score_model(x,bts[:,0,0,0]) \\\n",
    "            + torch.sqrt(step_size)*g*z\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026a71f-354c-491d-a6fe-b101d2f3b3a2",
   "metadata": {},
   "source": [
    "- <strong>Compute the likelihood on CIFAR10 (similar to the example provided on MNIST) for probabilistic flow ODE.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb056fc4-66ab-4d0c-b195-883356148061",
   "metadata": {},
   "source": [
    "The code that implements SBGM for CIFAR10 is available on \"Tutorial SBGM - CIFAR10.ipynb\". Minor changes were made to adapt the code to this dataset:\n",
    "\n",
    "- Changes in the model architecture made to enable the skip connections (guarantee that the encode-decode pairs have the same size)\n",
    "- Changed the number of input/output channels of the model from 1 to 3 (RGB)\n",
    "- Changed the shape of generated noise to be: (batch_size, 3, 32, 32)\n",
    "\n",
    "After training, the negative log-likelihood shows in average 5.217463 bits/dim. This score (lower is better) shows how different the likelihood estimation using the probabilistic flow ODE is from actual data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb281fd1-e9a7-4dfe-8578-d202c79445c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
